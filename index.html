<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=dpiI8CyVsrzWsJLBFKehGpLhv3qFjX7dUn1mYxfCXhI);ol.lst-kix_lkujsrvf7img-0{list-style-type:none}ol.lst-kix_lkujsrvf7img-1{list-style-type:none}ol.lst-kix_lkujsrvf7img-2{list-style-type:none}ol.lst-kix_r5zlxuhet7i-7.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-7 0}ol.lst-kix_lkujsrvf7img-3{list-style-type:none}ol.lst-kix_lkujsrvf7img-4{list-style-type:none}ol.lst-kix_lkujsrvf7img-5{list-style-type:none}ol.lst-kix_lkujsrvf7img-6{list-style-type:none}ol.lst-kix_lkujsrvf7img-7{list-style-type:none}ol.lst-kix_5f16krkcz2yy-6.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-6 0}.lst-kix_5f16krkcz2yy-4>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-4}ol.lst-kix_cr8bzav1190f-6.start{counter-reset:lst-ctn-kix_cr8bzav1190f-6 0}.lst-kix_cr8bzav1190f-3>li{counter-increment:lst-ctn-kix_cr8bzav1190f-3}ol.lst-kix_rokk8w1rd7yp-8.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-8 0}ol.lst-kix_lkujsrvf7img-4.start{counter-reset:lst-ctn-kix_lkujsrvf7img-4 0}.lst-kix_y3duqread3wx-1>li{counter-increment:lst-ctn-kix_y3duqread3wx-1}ol.lst-kix_lkujsrvf7img-8{list-style-type:none}.lst-kix_rokk8w1rd7yp-0>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-0}ol.lst-kix_cr8bzav1190f-0.start{counter-reset:lst-ctn-kix_cr8bzav1190f-0 0}.lst-kix_r5zlxuhet7i-7>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-7}ol.lst-kix_btu6pdepaqn-8.start{counter-reset:lst-ctn-kix_btu6pdepaqn-8 0}ol.lst-kix_r5zlxuhet7i-1.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-1 0}.lst-kix_lkujsrvf7img-4>li{counter-increment:lst-ctn-kix_lkujsrvf7img-4}ol.lst-kix_cr8bzav1190f-5{list-style-type:none}ol.lst-kix_y3duqread3wx-3.start{counter-reset:lst-ctn-kix_y3duqread3wx-3 0}ol.lst-kix_cr8bzav1190f-4{list-style-type:none}ol.lst-kix_cr8bzav1190f-3{list-style-type:none}ol.lst-kix_cr8bzav1190f-2{list-style-type:none}ol.lst-kix_cr8bzav1190f-1{list-style-type:none}ol.lst-kix_cr8bzav1190f-0{list-style-type:none}.lst-kix_cr8bzav1190f-5>li{counter-increment:lst-ctn-kix_cr8bzav1190f-5}.lst-kix_5f16krkcz2yy-2>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-2}ol.lst-kix_cr8bzav1190f-8{list-style-type:none}ol.lst-kix_cr8bzav1190f-7{list-style-type:none}ol.lst-kix_cr8bzav1190f-6{list-style-type:none}ol.lst-kix_r5zlxuhet7i-1{list-style-type:none}.lst-kix_cr8bzav1190f-0>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-0,decimal) ". "}ol.lst-kix_r5zlxuhet7i-0{list-style-type:none}ol.lst-kix_cr8bzav1190f-1.start{counter-reset:lst-ctn-kix_cr8bzav1190f-1 0}ol.lst-kix_r5zlxuhet7i-3{list-style-type:none}.lst-kix_btu6pdepaqn-0>li{counter-increment:lst-ctn-kix_btu6pdepaqn-0}ol.lst-kix_r5zlxuhet7i-2{list-style-type:none}.lst-kix_cr8bzav1190f-2>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-2,lower-roman) ". "}ol.lst-kix_btu6pdepaqn-2.start{counter-reset:lst-ctn-kix_btu6pdepaqn-2 0}.lst-kix_rokk8w1rd7yp-2>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-2}.lst-kix_cr8bzav1190f-1>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-1,lower-latin) ". "}ol.lst-kix_r5zlxuhet7i-2.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-2 0}ol.lst-kix_r5zlxuhet7i-8{list-style-type:none}ol.lst-kix_r5zlxuhet7i-5{list-style-type:none}ol.lst-kix_r5zlxuhet7i-4{list-style-type:none}ol.lst-kix_r5zlxuhet7i-7{list-style-type:none}.lst-kix_cr8bzav1190f-7>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-7,lower-latin) ". "}ol.lst-kix_r5zlxuhet7i-6{list-style-type:none}.lst-kix_cr8bzav1190f-6>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-6,decimal) ". "}.lst-kix_cr8bzav1190f-5>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-5,lower-roman) ". "}.lst-kix_r5zlxuhet7i-5>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-5}.lst-kix_cr8bzav1190f-4>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-4,lower-latin) ". "}.lst-kix_cr8bzav1190f-3>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-3,decimal) ". "}ol.lst-kix_btu6pdepaqn-3.start{counter-reset:lst-ctn-kix_btu6pdepaqn-3 0}ol.lst-kix_r5zlxuhet7i-8.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-8 0}ol.lst-kix_cr8bzav1190f-7.start{counter-reset:lst-ctn-kix_cr8bzav1190f-7 0}.lst-kix_btu6pdepaqn-7>li{counter-increment:lst-ctn-kix_btu6pdepaqn-7}.lst-kix_cr8bzav1190f-8>li:before{content:"" counter(lst-ctn-kix_cr8bzav1190f-8,lower-roman) ". "}.lst-kix_lkujsrvf7img-6>li{counter-increment:lst-ctn-kix_lkujsrvf7img-6}.lst-kix_rokk8w1rd7yp-5>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-5}.lst-kix_lkujsrvf7img-0>li{counter-increment:lst-ctn-kix_lkujsrvf7img-0}.lst-kix_y3duqread3wx-3>li{counter-increment:lst-ctn-kix_y3duqread3wx-3}.lst-kix_btu6pdepaqn-3>li{counter-increment:lst-ctn-kix_btu6pdepaqn-3}ol.lst-kix_r5zlxuhet7i-0.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-0 0}ol.lst-kix_btu6pdepaqn-4.start{counter-reset:lst-ctn-kix_btu6pdepaqn-4 0}ol.lst-kix_lkujsrvf7img-3.start{counter-reset:lst-ctn-kix_lkujsrvf7img-3 0}.lst-kix_y3duqread3wx-7>li{counter-increment:lst-ctn-kix_y3duqread3wx-7}.lst-kix_y3duqread3wx-8>li{counter-increment:lst-ctn-kix_y3duqread3wx-8}ol.lst-kix_5f16krkcz2yy-2.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-2 0}ol.lst-kix_rokk8w1rd7yp-1.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-1 0}.lst-kix_r5zlxuhet7i-2>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-2}ol.lst-kix_y3duqread3wx-7.start{counter-reset:lst-ctn-kix_y3duqread3wx-7 0}ol.lst-kix_btu6pdepaqn-7.start{counter-reset:lst-ctn-kix_btu6pdepaqn-7 0}.lst-kix_r5zlxuhet7i-4>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-4}.lst-kix_rokk8w1rd7yp-6>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-6}ol.lst-kix_cr8bzav1190f-2.start{counter-reset:lst-ctn-kix_cr8bzav1190f-2 0}ol.lst-kix_lkujsrvf7img-6.start{counter-reset:lst-ctn-kix_lkujsrvf7img-6 0}ol.lst-kix_rokk8w1rd7yp-4.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-4 0}.lst-kix_5f16krkcz2yy-8>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-8}.lst-kix_cr8bzav1190f-8>li{counter-increment:lst-ctn-kix_cr8bzav1190f-8}.lst-kix_btu6pdepaqn-8>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-8,lower-roman) ". "}.lst-kix_cr8bzav1190f-1>li{counter-increment:lst-ctn-kix_cr8bzav1190f-1}.lst-kix_btu6pdepaqn-6>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-6,decimal) ". "}.lst-kix_cr8bzav1190f-7>li{counter-increment:lst-ctn-kix_cr8bzav1190f-7}ol.lst-kix_cr8bzav1190f-5.start{counter-reset:lst-ctn-kix_cr8bzav1190f-5 0}.lst-kix_rokk8w1rd7yp-7>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-7}.lst-kix_btu6pdepaqn-2>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-2,lower-roman) ". "}ol.lst-kix_rokk8w1rd7yp-3.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-3 0}ol.lst-kix_5f16krkcz2yy-0.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-0 0}.lst-kix_5f16krkcz2yy-1>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-1,lower-latin) ". "}.lst-kix_btu6pdepaqn-4>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-4,lower-latin) ". "}ol.lst-kix_y3duqread3wx-7{list-style-type:none}.lst-kix_rokk8w1rd7yp-1>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-1,lower-latin) ". "}.lst-kix_5f16krkcz2yy-3>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-3}ol.lst-kix_y3duqread3wx-8{list-style-type:none}ol.lst-kix_y3duqread3wx-1{list-style-type:none}ol.lst-kix_y3duqread3wx-2{list-style-type:none}.lst-kix_btu6pdepaqn-2>li{counter-increment:lst-ctn-kix_btu6pdepaqn-2}ol.lst-kix_y3duqread3wx-0{list-style-type:none}ol.lst-kix_y3duqread3wx-5{list-style-type:none}ol.lst-kix_y3duqread3wx-6{list-style-type:none}ol.lst-kix_y3duqread3wx-3{list-style-type:none}ol.lst-kix_y3duqread3wx-4{list-style-type:none}ol.lst-kix_rokk8w1rd7yp-2.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-2 0}ol.lst-kix_cr8bzav1190f-4.start{counter-reset:lst-ctn-kix_cr8bzav1190f-4 0}ol.lst-kix_5f16krkcz2yy-1.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-1 0}.lst-kix_r5zlxuhet7i-3>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-3}.lst-kix_lkujsrvf7img-2>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-2,lower-roman) ". "}ol.lst-kix_y3duqread3wx-8.start{counter-reset:lst-ctn-kix_y3duqread3wx-8 0}ol.lst-kix_btu6pdepaqn-6.start{counter-reset:lst-ctn-kix_btu6pdepaqn-6 0}.lst-kix_lkujsrvf7img-4>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-4,lower-latin) ". "}ol.lst-kix_lkujsrvf7img-5.start{counter-reset:lst-ctn-kix_lkujsrvf7img-5 0}.lst-kix_lkujsrvf7img-8>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-8,lower-roman) ". "}ol.lst-kix_rokk8w1rd7yp-5.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-5 0}.lst-kix_lkujsrvf7img-7>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-7,lower-latin) ". "}.lst-kix_r5zlxuhet7i-6>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-6,decimal) ". "}.lst-kix_r5zlxuhet7i-8>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-8,lower-roman) ". "}ol.lst-kix_y3duqread3wx-0.start{counter-reset:lst-ctn-kix_y3duqread3wx-0 0}.lst-kix_lkujsrvf7img-6>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-6,decimal) ". "}.lst-kix_r5zlxuhet7i-5>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-5,lower-roman) ". "}ol.lst-kix_lkujsrvf7img-7.start{counter-reset:lst-ctn-kix_lkujsrvf7img-7 0}.lst-kix_r5zlxuhet7i-7>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-7,lower-latin) ". "}.lst-kix_lkujsrvf7img-0>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-0,decimal) ". "}.lst-kix_rokk8w1rd7yp-8>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-8,lower-roman) ". "}.lst-kix_cr8bzav1190f-4>li{counter-increment:lst-ctn-kix_cr8bzav1190f-4}.lst-kix_rokk8w1rd7yp-7>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-7,lower-latin) ". "}.lst-kix_y3duqread3wx-2>li{counter-increment:lst-ctn-kix_y3duqread3wx-2}.lst-kix_btu6pdepaqn-8>li{counter-increment:lst-ctn-kix_btu6pdepaqn-8}.lst-kix_rokk8w1rd7yp-6>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-6,decimal) ". "}.lst-kix_lkujsrvf7img-5>li{counter-increment:lst-ctn-kix_lkujsrvf7img-5}.lst-kix_rokk8w1rd7yp-4>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-4,lower-latin) ". "}.lst-kix_r5zlxuhet7i-8>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-8}.lst-kix_rokk8w1rd7yp-3>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-3,decimal) ". "}.lst-kix_rokk8w1rd7yp-5>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-5,lower-roman) ". "}ol.lst-kix_cr8bzav1190f-3.start{counter-reset:lst-ctn-kix_cr8bzav1190f-3 0}.lst-kix_y3duqread3wx-2>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-2,lower-roman) ". "}.lst-kix_lkujsrvf7img-7>li{counter-increment:lst-ctn-kix_lkujsrvf7img-7}ol.lst-kix_rokk8w1rd7yp-8{list-style-type:none}.lst-kix_y3duqread3wx-3>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-3,decimal) ". "}ol.lst-kix_y3duqread3wx-6.start{counter-reset:lst-ctn-kix_y3duqread3wx-6 0}ol.lst-kix_rokk8w1rd7yp-5{list-style-type:none}ol.lst-kix_rokk8w1rd7yp-4{list-style-type:none}ol.lst-kix_5f16krkcz2yy-3.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-3 0}.lst-kix_btu6pdepaqn-1>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-1,lower-latin) ". "}ol.lst-kix_rokk8w1rd7yp-7{list-style-type:none}ol.lst-kix_rokk8w1rd7yp-6{list-style-type:none}.lst-kix_5f16krkcz2yy-3>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-3,decimal) ". "}.lst-kix_y3duqread3wx-0>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-0,decimal) ". "}ol.lst-kix_rokk8w1rd7yp-1{list-style-type:none}ol.lst-kix_btu6pdepaqn-5.start{counter-reset:lst-ctn-kix_btu6pdepaqn-5 0}.lst-kix_y3duqread3wx-8>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-8,lower-roman) ". "}ol.lst-kix_rokk8w1rd7yp-0{list-style-type:none}.lst-kix_btu6pdepaqn-0>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-0,decimal) ". "}.lst-kix_y3duqread3wx-1>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-1,lower-latin) ". "}ol.lst-kix_rokk8w1rd7yp-3{list-style-type:none}ol.lst-kix_rokk8w1rd7yp-2{list-style-type:none}.lst-kix_5f16krkcz2yy-4>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-4,lower-latin) ". "}.lst-kix_rokk8w1rd7yp-1>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-1}.lst-kix_5f16krkcz2yy-5>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-5}.lst-kix_r5zlxuhet7i-0>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-0,decimal) ". "}.lst-kix_5f16krkcz2yy-5>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-5,lower-roman) ". "}.lst-kix_5f16krkcz2yy-7>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-7,lower-latin) ". "}ol.lst-kix_r5zlxuhet7i-4.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-4 0}.lst-kix_y3duqread3wx-7>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-7,lower-latin) ". "}.lst-kix_r5zlxuhet7i-1>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-1,lower-latin) ". "}.lst-kix_5f16krkcz2yy-6>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-6,decimal) ". "}.lst-kix_y3duqread3wx-5>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-5,lower-roman) ". "}.lst-kix_y3duqread3wx-6>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-6,decimal) ". "}.lst-kix_r5zlxuhet7i-2>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-2,lower-roman) ". "}.lst-kix_r5zlxuhet7i-4>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-4,lower-latin) ". "}.lst-kix_y3duqread3wx-4>li:before{content:"" counter(lst-ctn-kix_y3duqread3wx-4,lower-latin) ". "}.lst-kix_cr8bzav1190f-2>li{counter-increment:lst-ctn-kix_cr8bzav1190f-2}.lst-kix_r5zlxuhet7i-3>li:before{content:"" counter(lst-ctn-kix_r5zlxuhet7i-3,decimal) ". "}.lst-kix_5f16krkcz2yy-8>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-8,lower-roman) ". "}ol.lst-kix_5f16krkcz2yy-4.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-4 0}.lst-kix_5f16krkcz2yy-1>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-1}.lst-kix_cr8bzav1190f-6>li{counter-increment:lst-ctn-kix_cr8bzav1190f-6}ol.lst-kix_rokk8w1rd7yp-0.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-0 0}ol.lst-kix_y3duqread3wx-5.start{counter-reset:lst-ctn-kix_y3duqread3wx-5 0}.lst-kix_btu6pdepaqn-1>li{counter-increment:lst-ctn-kix_btu6pdepaqn-1}ol.lst-kix_lkujsrvf7img-1.start{counter-reset:lst-ctn-kix_lkujsrvf7img-1 0}.lst-kix_cr8bzav1190f-0>li{counter-increment:lst-ctn-kix_cr8bzav1190f-0}.lst-kix_5f16krkcz2yy-7>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-7}ol.lst-kix_cr8bzav1190f-8.start{counter-reset:lst-ctn-kix_cr8bzav1190f-8 0}.lst-kix_y3duqread3wx-0>li{counter-increment:lst-ctn-kix_y3duqread3wx-0}ol.lst-kix_rokk8w1rd7yp-6.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-6 0}.lst-kix_btu6pdepaqn-4>li{counter-increment:lst-ctn-kix_btu6pdepaqn-4}.lst-kix_lkujsrvf7img-3>li{counter-increment:lst-ctn-kix_lkujsrvf7img-3}ol.lst-kix_lkujsrvf7img-8.start{counter-reset:lst-ctn-kix_lkujsrvf7img-8 0}ol.lst-kix_lkujsrvf7img-2.start{counter-reset:lst-ctn-kix_lkujsrvf7img-2 0}.lst-kix_rokk8w1rd7yp-8>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-8}.lst-kix_y3duqread3wx-6>li{counter-increment:lst-ctn-kix_y3duqread3wx-6}ol.lst-kix_lkujsrvf7img-0.start{counter-reset:lst-ctn-kix_lkujsrvf7img-0 0}.lst-kix_rokk8w1rd7yp-4>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-4}ol.lst-kix_y3duqread3wx-4.start{counter-reset:lst-ctn-kix_y3duqread3wx-4 0}ol.lst-kix_r5zlxuhet7i-3.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-3 0}ol.lst-kix_btu6pdepaqn-0{list-style-type:none}ol.lst-kix_btu6pdepaqn-2{list-style-type:none}ol.lst-kix_btu6pdepaqn-1{list-style-type:none}ol.lst-kix_btu6pdepaqn-4{list-style-type:none}ol.lst-kix_btu6pdepaqn-3{list-style-type:none}ol.lst-kix_5f16krkcz2yy-5.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-5 0}ol.lst-kix_btu6pdepaqn-6{list-style-type:none}ol.lst-kix_btu6pdepaqn-5{list-style-type:none}ol.lst-kix_btu6pdepaqn-8{list-style-type:none}ol.lst-kix_btu6pdepaqn-7{list-style-type:none}.lst-kix_lkujsrvf7img-1>li{counter-increment:lst-ctn-kix_lkujsrvf7img-1}.lst-kix_rokk8w1rd7yp-3>li{counter-increment:lst-ctn-kix_rokk8w1rd7yp-3}ol.lst-kix_btu6pdepaqn-1.start{counter-reset:lst-ctn-kix_btu6pdepaqn-1 0}.lst-kix_r5zlxuhet7i-1>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-1}ol.lst-kix_rokk8w1rd7yp-7.start{counter-reset:lst-ctn-kix_rokk8w1rd7yp-7 0}.lst-kix_btu6pdepaqn-6>li{counter-increment:lst-ctn-kix_btu6pdepaqn-6}.lst-kix_y3duqread3wx-4>li{counter-increment:lst-ctn-kix_y3duqread3wx-4}ol.lst-kix_r5zlxuhet7i-5.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-5 0}.lst-kix_btu6pdepaqn-7>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-7,lower-latin) ". "}ol.lst-kix_5f16krkcz2yy-1{list-style-type:none}ol.lst-kix_5f16krkcz2yy-0{list-style-type:none}ol.lst-kix_5f16krkcz2yy-8.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-8 0}.lst-kix_btu6pdepaqn-5>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-5,lower-roman) ". "}ol.lst-kix_y3duqread3wx-2.start{counter-reset:lst-ctn-kix_y3duqread3wx-2 0}.lst-kix_btu6pdepaqn-5>li{counter-increment:lst-ctn-kix_btu6pdepaqn-5}.lst-kix_lkujsrvf7img-2>li{counter-increment:lst-ctn-kix_lkujsrvf7img-2}.lst-kix_y3duqread3wx-5>li{counter-increment:lst-ctn-kix_y3duqread3wx-5}.lst-kix_5f16krkcz2yy-2>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-2,lower-roman) ". "}ol.lst-kix_5f16krkcz2yy-8{list-style-type:none}ol.lst-kix_5f16krkcz2yy-7{list-style-type:none}ol.lst-kix_5f16krkcz2yy-6{list-style-type:none}ol.lst-kix_5f16krkcz2yy-5{list-style-type:none}ol.lst-kix_5f16krkcz2yy-4{list-style-type:none}.lst-kix_btu6pdepaqn-3>li:before{content:"" counter(lst-ctn-kix_btu6pdepaqn-3,decimal) ". "}.lst-kix_lkujsrvf7img-8>li{counter-increment:lst-ctn-kix_lkujsrvf7img-8}ol.lst-kix_5f16krkcz2yy-3{list-style-type:none}.lst-kix_5f16krkcz2yy-0>li:before{content:"" counter(lst-ctn-kix_5f16krkcz2yy-0,decimal) ". "}ol.lst-kix_5f16krkcz2yy-2{list-style-type:none}.lst-kix_rokk8w1rd7yp-0>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-0,decimal) ". "}.lst-kix_5f16krkcz2yy-0>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-0}.lst-kix_rokk8w1rd7yp-2>li:before{content:"" counter(lst-ctn-kix_rokk8w1rd7yp-2,lower-roman) ". "}ol.lst-kix_r5zlxuhet7i-6.start{counter-reset:lst-ctn-kix_r5zlxuhet7i-6 0}ol.lst-kix_y3duqread3wx-1.start{counter-reset:lst-ctn-kix_y3duqread3wx-1 0}.lst-kix_5f16krkcz2yy-6>li{counter-increment:lst-ctn-kix_5f16krkcz2yy-6}ol.lst-kix_5f16krkcz2yy-7.start{counter-reset:lst-ctn-kix_5f16krkcz2yy-7 0}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_r5zlxuhet7i-6>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-6}.lst-kix_lkujsrvf7img-1>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-1,lower-latin) ". "}ol.lst-kix_btu6pdepaqn-0.start{counter-reset:lst-ctn-kix_btu6pdepaqn-0 0}.lst-kix_lkujsrvf7img-3>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-3,decimal) ". "}.lst-kix_lkujsrvf7img-5>li:before{content:"" counter(lst-ctn-kix_lkujsrvf7img-5,lower-roman) ". "}.lst-kix_r5zlxuhet7i-0>li{counter-increment:lst-ctn-kix_r5zlxuhet7i-0}ol{margin:0;padding:0}table td,table th{padding:0}.c15{border-right-style:solid;padding:2pt 2pt 2pt 6pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;width:47.2pt;border-top-color:#000000;border-bottom-style:solid}.c36{border-right-style:solid;padding:6pt 6pt 2pt 6pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;width:136.5pt;border-top-color:#000000;border-bottom-style:solid}.c35{border-right-style:solid;padding:6pt 6pt 2pt 6pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;width:157.5pt;border-top-color:#000000;border-bottom-style:solid}.c43{border-right-style:solid;padding:2pt 2pt 2pt 6pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;width:109.5pt;border-top-color:#000000;border-bottom-style:solid}.c37{border-right-style:solid;padding:2pt 2pt 2pt 6pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;width:157.5pt;border-top-color:#000000;border-bottom-style:solid}.c29{border-right-style:solid;padding:6pt 6pt 2pt 6pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;width:109.5pt;border-top-color:#000000;border-bottom-style:solid}.c28{border-right-style:solid;padding:2pt 2pt 2pt 6pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;width:136.5pt;border-top-color:#000000;border-bottom-style:solid}.c42{border-right-style:solid;padding:6pt 6pt 2pt 6pt;border-bottom-color:#000000;border-top-width:0pt;border-right-width:0pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:0pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:0pt;width:47.2pt;border-top-color:#000000;border-bottom-style:solid}.c24{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:93pt;border-top-color:#000000;border-bottom-style:solid}.c8{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:78pt;border-top-color:#000000;border-bottom-style:solid}.c13{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:63pt;border-top-color:#000000;border-bottom-style:solid}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:12pt}.c11{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c19{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c3{color:#1586c3;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Roboto";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c6{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c33{padding-top:14pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c20{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:center}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c32{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c2{color:#000000;text-decoration:none;vertical-align:baseline;font-size:12pt;font-style:normal}.c26{color:#1586c3;text-decoration:none;vertical-align:baseline;font-size:14pt;font-style:normal}.c18{color:#1586c3;text-decoration:none;vertical-align:baseline;font-size:20pt;font-style:normal}.c16{color:#000000;text-decoration:none;vertical-align:baseline;font-size:9pt;font-style:normal}.c17{color:#1586c3;text-decoration:none;vertical-align:baseline;font-size:12pt;font-style:normal}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c22{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1586c3;text-decoration:underline}.c34{border-spacing:0;border-collapse:collapse;margin-right:auto}.c21{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c12{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c30{font-weight:400;font-size:11pt;font-family:"Arial"}.c38{font-size:20pt;color:#1586c3}.c27{padding:0;margin:0}.c14{margin-left:36pt;padding-left:0pt}.c0{font-weight:400;font-family:"Roboto"}.c23{color:inherit;text-decoration:inherit}.c25{height:0pt}.c7{font-weight:700}.c41{font-size:9pt}.c10{font-family:"Roboto"}.c44{height:18pt}.c31{height:23.4pt}.c40{margin-left:36pt}.c39{text-indent:36pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:12pt;font-family:"Roboto"}p{margin:0;color:#000000;font-size:12pt;font-family:"Roboto"}h1{padding-top:20pt;color:#1586c3;font-weight:700;font-size:20pt;padding-bottom:6pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#1586c3;font-weight:700;font-size:20pt;padding-bottom:6pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#1586c3;font-weight:700;font-size:16pt;padding-bottom:4pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#1586c3;font-size:14pt;padding-bottom:4pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}/* Centering the content */

/* Reset default margin and padding for all elements */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

/* Set body to use flexbox to center content */
body {
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    min-height: 100vh;
    text-align: center;
}

/* Ensure that images and tables within the body are not stretched */
img, table {
    max-width: 100%;
    height: auto;
}

/* Center tables specifically, as they are block elements */
table {
    margin-left: auto;
    margin-right: auto;
}

/* You may also want to center the content within table cells */
td, th {
    text-align: center;
}

</style></head><body class="c12 doc-content"><div><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 50.29px; height: 70.50px;"><img alt="" src="images/image2.png" style="width: 50.29px; height: 70.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p></div><h2 class="c11" id="h.zlquy2mi1yx"><span>Node Operator </span><span class="c7 c10 c38">Scoring</span></h2><p class="c5"><span>To create a scoring system for Node Operators (</span><span>NOs</span><span>), it&rsquo;s critical to first identify what outcome the system will optimize for. At the highest level, we want the &ldquo;best&rdquo; set of NO&#39;s, such that stakers can earn the greatest APY over an infinite period. Doing so requires that validators generate competitive premiums, while also avoiding loss of ETH.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>The Lido scorecard</span><span class="c0">&nbsp;identifie</span><span>s</span><span class="c0">&nbsp;some factors that</span><span>&nbsp;would allow it to reach these </span><span class="c2 c0">goals:</span></p><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_r5zlxuhet7i-0 start" start="1"><li class="c5 c14 li-bullet-0"><span>NO&#39;s</span><span class="c2 c0">&nbsp;run their own nodes (no white-labeling)</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Good performance</span></li><li class="c5 c14 li-bullet-0"><span>NO&#39;s</span><span class="c0">&nbsp;should earn enough to build a profitable, </span><span>dependable </span><span class="c2 c0">staking business</span></li><li class="c5 c14 li-bullet-0"><span class="c0">No operator has more than 1% of </span><span>the </span><span class="c2 c0">total stake</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Distributed geographically and jurisdictionally</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Distributed variation of on-premise infra and different cloud providers</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Best practices in security and key management</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Client Diversity</span></li><li class="c5 c14 li-bullet-0"><span class="c0">Node </span><span>NO&#39;s</span><span class="c2 c0">&nbsp;are disincentivized from acting maliciously</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Lido DAO can&rsquo;t suddenly change the validator set</span></li><li class="c5 c14 li-bullet-0"><span class="c0">There&rsquo;s a way for </span><span>permissionless</span><span class="c0">&nbsp;</span><span>entry to</span><span class="c0">&nbsp;the set</span></li></ol><h2 class="c11" id="h.pkp0j4uzuoag"><span class="c18 c7 c10">Building a NO Scoring System</span></h2><p class="c5"><span>Before we look at possible datasets and metrics, it&rsquo;s necessary to </span><span>first decide</span><span class="c2 c0">&nbsp;on a desired scoring approach. Our approach will influence the usefulness of datasets and our tolerance for their faults.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Many of the Lido scorecard goals can be distilled down to reducing risk while simultaneously achieving &ldquo;good performance&rdquo;.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Lido has already committed to </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://research.lido.fi/t/lido-on-ethereum-community-validation-manifesto/3331&amp;sa=D&amp;source=editors&amp;ust=1700278667358676&amp;usg=AOvVaw0Zr2WDjMOri2CbFz2T8YRe">expanding diversity</a></span><span class="c2 c0">&nbsp;to reduce risk across three dimensions; technical, geographical, and jurisdictional.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Viewing a scoring system through the lens of risk will allow us to mitigate losses and hence earn a respectable APY over a long timeframe. Therefore, it&rsquo;s from a risk standpoint that we should review possible data for inclusion in our scoring to craft a healthy and resilient validator set.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The decisions that NO&rsquo;s make can influence their rewards, more significantly than I expected. However, the financial penalty of mistakes is so great as to overwhelm many of these optimizations over the long run. We should look to include performance data in scoring, it matters and we cannot expect stakers to have an infinite timeframe. But we must simultaneously ensure that our primary focus is on managing risk.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, I don&rsquo;t believe it&rsquo;s possible to score NO&rsquo;s without using datasets that examine the largest risks and that will require using off-chain data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">To include these datasets, it will be necessary to operate a less-trustless scoring system. Such data is likely to rely on NO&rsquo;s truthfulness. The tradeoffs are obvious - to score the most impactful factors you introduce the risk of NO&rsquo;s lying.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>It will be necessary to create incentives for truthfulness where possible, checks to validate their claims, and a system to investigate red flags and punish those in violation.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">In the next section, we will review the existing scoring systems and then examine specific datasets for their quality, characteristics, and overall usability. We&rsquo;ll also consider how we can create new data, beyond what is currently available, to fill gaps in the existing datasets.</span></p><h1 class="c19" id="h.damn9eagqs13"><span>Existing Scoring Systems</span></h1><h2 class="c11" id="h.n1uqttoc9mcu"><span class="c18 c7 c10">Rated Network</span></h2><p class="c5"><span>Rated Network operates one of the most popular scoring systems. The Rated Validator Effectiveness Rating (</span><span>RAVER</span><span class="c2 c0">) is a &ldquo;measure of how well a validator has been performing its deterministic duties over time&rdquo;.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">It aims to attribute to NO&#39;s &ldquo;only what is under their direct control&rdquo;. It&rsquo;s evident post-merge that the performance of duties correlates only loosely to validator rewards. Hence, they believe that APY is not a sufficient measure of operator performance.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">The Rated scoring system:</span></p><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_rokk8w1rd7yp-0 start" start="1"><li class="c5 c14 li-bullet-0"><span class="c2 c0">proposer_effectiveness == [non_empty_blocks + empty_blocks * 0.25] / total_proposer_slots_attributed</span></li></ol><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_rokk8w1rd7yp-0" start="2"><li class="c5 c14 li-bullet-0"><span class="c2 c0">attester_effectiveness == participation_rate * correctness_score / aggregate_inclusion_delay</span></li></ol><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_rokk8w1rd7yp-0" start="3"><li class="c5 c14 li-bullet-0"><span class="c2 c0">validator_effectiveness == [3/8 * proposer_effectiveness] + [5/8 * attester_effectiveness]</span></li></ol><p class="c1"><span class="c4"></span></p><h3 class="c6" id="h.3zvusn4jd8e7"><span class="c3">Proposal effectiveness</span></h3><p class="c5"><span class="c2 c0">The calculation for proposer effectiveness in Rated post-merge is:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">proposer_effectiveness == [non_empty_blocks + empty_blocks * 0.25] / total_proposer_slots_attributed</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This formula scores how many times a validator has successfully proposed a block out of the times that they were awarded proposer duties.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 148.00px;"><img alt="" src="images/image4.png" style="width: 624.00px; height: 148.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For cases where the EL is empty, they score 0.25, rather than the expected 0.5. This harsher penalization is because of their opinion that validators exist to facilitate transactions and therefore an empty EL is a severe failure to contribute to the network.</span></p><h3 class="c6" id="h.caocky8c38s1"><span class="c3">Attestation effectiveness</span></h3><p class="c5"><span class="c2 c0">attester_effectiveness == participation_rate * correctness_score / aggregate_inclusion_delay</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">There are now additional penalties for cases when the attestation does not get included in a timely manner; namely within sqrt(EPOCH_LENGTH) or 5 slots. But Rated does not use this when calculating participation. When a validator is more than 5 slots late, but less than 32 slots late, they will not be negatively scored in Rated, however, it would be penalized on the blockchain.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Rated prioritizes generalizability and legibility in their design goals, hence not scoring this lateness. For our scoring system, this is unlikely to be the best approach because it would allow NO&#39;s to accumulate penalties and missed rewards without being negatively scored.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This can be moderated by monitoring of inclusion delay, which can be a helpful signal for predicting an NO&#39;s propensity for lateness. Rated does not use inclusion delay, instead looking at lateness as binary based on correctness.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">However, it&rsquo;s not obvious that the inclusion delay contains zero useful information. If a validator is attesting extremely slowly, but never slow enough to be penalized, this matters to us. This slowness suggests that for a given volatility in their network or hardware performance, they will be more likely to be so delayed as to result in a penalty when compared to other NO&#39;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">While the Rated system exists to track existing performance in a backward-looking fashion, our system must make forward predictions to minimize risk and maximize the quality of the set. Therefore, we must attempt to weigh the risk that something will happen, not just track whether it has in the past.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Due to the rare occurrence of events on the Ethereum blockchain, particularly slashing but also penalties, tracking in a binary fashion is unsuitable for our purposes. We must be more predictive and value magnitude not just frequency.</span></p><h3 class="c6" id="h.otyrxv4yytrp"><span class="c3">Validator effectiveness</span></h3><p class="c5"><span class="c2 c0">validator_effectiveness == [3/8 * proposer_effectiveness] + [5/8 * attester_effectiveness]</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Currently, Rated applies disproportionate weighting to proposer_effectiveness in relation to the expected long-term reward distribution of &#8539; to &#8542;.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">They have observed that &ldquo;execution to consensus layer rewards come at a 1:4 ratio&rdquo; but expect that the ratio will become &ldquo;more balanced over time&rdquo; once we see:</span></p><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_btu6pdepaqn-0 start" start="1"><li class="c5 c14 li-bullet-0"><span class="c2 c0">More active validators on the Beacon Chain</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">More adoption of MEV Relays and out-of-protocol PBS</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Greater demand for blockspace</span></li></ol><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Weighting proposer and attester effectiveness based on existing data rather than the long-run expectation seems smart. If we choose to score based on the long-run expectation we risk lower rewards in the interim. With an unknown period until the long-run average is achieved, it&rsquo;s necessary to follow Rated and adopt a non-standard weighting.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Currently, more recent data is significantly closer to the long-run expectation so I would expect Rated to adjust their proportions in the future.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Instead of dictating a fixed weighting, we can track the proportion of rewards across the network across some period and apply it on a monthly cadence. This should allow the system to be sufficiently dynamic without requiring expensive tracking of a large number of data points.</span></p><h3 class="c6" id="h.rbmownc0pxl3"><span class="c3">Slashing</span></h3><p class="c5"><span class="c2 c0">RAVER currently does not include slashing, but Rated appears to be working to add it. For our purposes slashing occurrence is critical for scoring a NO. Slashing is the most serious offense and not tracking it creates a serious hole in the scoring that would result in highly perverse incentives.</span></p><h3 class="c6" id="h.qbeymr6q9enk"><span class="c3">Sync committees</span></h3><p class="c5"><span class="c2 c0">RAVER currently does not factor in whether a validator is part of the sync committee or not. They say that because of the &ldquo;stochastic nature of sync committee selection and the low probability of a single validator to be selected in a sync committee set, we have opted for not including sync committee performance&rdquo;.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">It&rsquo;s important to recognize that RAVER operates by scoring each validator separately and then averaging the scores for higher-level aggregations like NO&#39;s and deposit addresses.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Not factoring for sync committees makes sense because of the low likelihood of an individual validator being included. When looking at shorter timeframes the sync committee inclusion is too deterministic and would unfairly impact small or solo NO&#39;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Scoring sync committees differently could also add perverse incentives where NO&rsquo;s want to avoid missing sync committees and therefore defer maintenance or necessary downtime.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This could encourage NO&rsquo;s to take offline a subset of a cluster of validators on a single server to perform some maintenance while trying to keep the validators in the sync committee online. This adds the additional risk of slashing if transferring of keys between servers is required.</span></p><h3 class="c6" id="h.isdajnotr5gh"><span class="c3">Penalties and Missed Rewards</span></h3><p class="c5"><span class="c2 c0">Rated appears to attempt to follow the existing Ethereum spec when calculating their penalties and missed rewards for attestations.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We noted that the RAVER attester effectiveness score doesn&rsquo;t appear to measure correctness and participation exactly as the spec. However, the underlying penalties and missed rewards data available via their API seem to follow the specification precisely.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Calculating missed rewards on the execution layer is much more challenging than for attestation rewards and there are multiple seemingly acceptable approaches.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Rated looks at four approaches, and will be offering the first two in their API:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Approach 1: Simple average of block value in an epoch</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>EL rewards can be averaged for a period by dividing the sum of rewards per block by the </span><span>number</span><span class="c2 c0">&nbsp;of proposed blocks in the period.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Rated notes that this approach is simple to understand, calculable with only on-chain data, and replicable. But it flattens the impact of MEV. One operator running mev-boost would earn significantly more for the same blocks, on average, compared to producing vanilla blocks. Taking a simple average will falsely reduce the missed rewards of those using mev-boost and increase the estimated missed rewards of those not.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Lastly, block rewards have a high variance in reality. If the missed block was wildly profitable, the truly missed rewards were much larger than the average, and vice versa.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Approach 2: Referencing relay bids for the opportunity cost</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">You can call various relay APIs for a specific block to understand what rewards were possible, then take an average.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Rated notes that they have &ldquo;found that in the majority of cases winning_bid &ne; max_bid&rdquo;, and therefore opt to use the average of all builder bids, rather than solely the max bid.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">It&rsquo;s likely that &ldquo;bids keep arriving after the winning_bid gets picked; naturally these bids pack more transactions&rdquo; which explains why the max bid is often higher than the winning bids.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This approach is perhaps the closest approximation of missed rewards because it references the market clearing price at the time that block was proposed. The problem with taking an average of all bids is that you will likely approximate the median, given the expected linear increase in bids. Meanwhile, as I&rsquo;ll show later, most NO&rsquo;s select a bid before the slot has started. So, their missed rewards are expected to be lower than what this metric would suggest.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Lastly, using relay data will unfairly punish those NO&rsquo;s not using mev-boost blocks as frequently and rely on the availability of data not on-chain.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Approach 3: Referencing the next block produced</span><span><br><br>&ldquo;</span><span>The validator who missed the proposal would have had access to the same transactions as the next proposer and could then have at least built the same block with the same transactions and corresponding fees.</span><span class="c2 c0">&rdquo;</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The problem with this approach is that the next block can include transactions that did not exist at the time that the initial validator would have proposed a block. Therefore, this can, and likely will, increase the value of the next block produced because the greater number of transactions potentially allows for more MEV extraction.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Approach 4: Abstracting to the operator level</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When aggregating at the operator level we can use information about their ratio of mev-boosted and vanilla blocks to get a more precise approximation of their missed rewards.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This approach could allow us to more accurately predict the missed rewards for a specific operator. However, the approach Rated suggests still relies on the average rewards for vanilla blocks and an average of relay bids, multiplied by the ratio of each type.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">In reality, NO&#39;s are likely only opting for vanilla blocks when the bids are below their min-bid threshold or when the mev-boost API fails to reply in time for the proposal.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, using only the average of vanilla blocks doesn&rsquo;t give a particularly precise estimate of missed rewards, because it doesn&rsquo;t know how far below min-bid the rewards were. Or, if the API simply didn&rsquo;t respond.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Lastly, it doesn&rsquo;t attempt to decipher if the specific missed block would have been proposed using a relay or as a vanilla block.</span></p><p class="c1"><span class="c2 c0"></span></p><h3 class="c6" id="h.wzimjharr9zu"><span class="c3">Scoring Missed EL Rewards Accurately</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Instead, I would propose that we try to encapsulate more information when estimating missed rewards. While Rated has the hard task of trying to generalize their scoring across all validators, we are fortunate to have the much easier task of only scoring a known group of NO&#39;s, which we can communicate with.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Each operator can, and should, make public what min-bid threshold they set. Lido DAO has already soft-enforced a list of &ldquo;</span><span>must-include some&rdquo; and &ldquo;may include&rdquo; relays, so we could rely on these for getting the builder&#39;s bids.</span><span class="c2 c0">&nbsp;Specifically, NO&rsquo;s do not have to use every relay in that list they must use at least one. However, because it&rsquo;s impossible to know ahead of time which they will use, we will need to include all of them.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We can take all of the bids that existed on these relays for the block and choose the highest available bid at the average timestamp when NO&rsquo;s select a bid.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">If this bid is above the min-bid threshold for the operator, we will presume that this is the reward they have missed. If it&rsquo;s below their min-bid threshold, then we must presume that they would have created a vanilla block.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The value of a vanilla block can be calculated by taking the EL rewards earned per vanilla block in a TBD period and dividing it by the number of vanilla blocks.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Theoretically, this should deliver a more accurate representation of the missed rewards.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The downsides to this approach are:</span></p><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_y3duqread3wx-0 start" start="1"><li class="c5 c14 li-bullet-0"><span class="c2 c0">It&rsquo;s heavy to calculate because it relies on pulling data from each missed block, and from many different relay APIs, rather than using aggregates for an epoch.<br></span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">The number of vanilla blocks is relatively low and so there is variability in EL rewards for these blocks. However, the variability is low enough to be preferable to taking an average of all blocks, which would include mev-boosted blocks.<br></span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">We rely on NO&#39;s truthfully updating their min-bid in our system whenever they change it locally. This adds extra complexity to the creation of the system.</span></li></ol><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">If this approach is undesirable due to complexity, I would recommend opting to use approach two and referencing relay bids. The downside is that you unfairly punish those not using mev-boost and those with higher min-bid thresholds, which risks adding censorship to the network.</span></p><h3 class="c6" id="h.cq4ttvd951e"><span class="c3">Aggregation</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Lastly, we&rsquo;ll look at how Rated aggregates across groups of validators and periods. Surprisingly, the different approaches to aggregation can meaningfully impact scores.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For groups of validators i.e. aggregation by operator or deposit address, Rated uses a validator-up approach. They simply take an average of each metric score in the group of validators and attribute that to the operator.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">While Rated does not use slashing in their RAVER scoring, it&rsquo;s likely not sufficient to treat rare events like slashing and perhaps even missed blocks as averages. Taking an average will compress the dataset, making an operator who has a few validators slashed score very similar to those who have had no slashing events.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For rarer events, it&rsquo;s likely better to use a binning approach, such that even having only 0.01% of validators slashed would give an operator a meaningfully poorer score than those without slashes.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When aggregating by period Rated takes an average of daily averages. For example, when looking at 30-day inclusion-delay they would calculate the average inclusion-delay for each 24-hour daily period. Then, they take an average of those 30 data points. This calculation is different from taking the inclusion-delay of each attestation over the 30 days and calculating the average.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The former approach, which Rated uses, is superior. It reduces the amount of calculation required because past days&#39; data can be aggregated and stored to a daily group, rather than requiring us to iterate across the data each time the calculation is run.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">More importantly, it prevents changes in the number of validators in a group from impacting the result.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For example, if you have 10 validators for the first 15 days, you have 225 * 15 * 10 ~ &nbsp;33,750 attestations.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Then, if you have 20 validators for the next 15 days, you have 225 * 15 * 20 ~ 67,500 attestations.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">If you average across all attestations then the last 15-days will represent &#8532; of the result, making the first 15-days of data less impactful. Whereas if you aggregate by day first, each day in the 30 days of data is treated equally.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The positive to this Rated approach is that it prevents sudden changes in the number of validators from skewing the data such that it&rsquo;s unreliable. The downside is the inverse, which is that this makes the data less responsive. For example, in the case where an operator spins up many new validators on the same hardware, this could meaningfully decrease performance. Yet, the data will not reflect this as quickly because we&rsquo;re aggregating first by day.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Overall, I think the tradeoffs are worth it because it&rsquo;s unlikely that the number of validators an operator has will change so rapidly as to cause meaningful issues in the data.</span></p><h2 class="c11" id="h.8lr2jr76egpk"><span class="c18 c7 c10">Observatory Zone Scoring</span></h2><p class="c5"><span>(</span><span class="c21"><a class="c23" href="https://www.google.com/url?q=https://observatory.zone/cosmos-hub/validators&amp;sa=D&amp;source=editors&amp;ust=1700278667373824&amp;usg=AOvVaw2mYpLoFz6qCcas3NFdQ2Bz">https://observatory.zone/cosmos-hub/validators</a></span><span class="c2 c0">)</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Observatory Zone uses a radically different scoring approach. While Observatory Zone has</span><span>&nbsp;very low sensor participation</span><span>&nbsp;to report data, the logic of the whitepaper (</span><span>avoid downloading, as I&rsquo;m currently getting anti-virus reports saying the PDF contains a trojan&hellip; could be a false report but be cautious</span><span class="c2 c0">) is still interesting.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Observatory Zone does not attempt to score individual validators and rank them. Instead, its goal is to score blockchains based on their decentralization, performance, and governance.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Their system is very simple so we will only discuss it briefly and note any interesting data points that we might try to replicate.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Outside of on-chain performance data, they rely heavily on scoring decentralization. To do so, they rely on the number of validators, and geographic and ISP-level concentration data. When calculating ISP and geographic concentration they calculate at the node level, without attempting to try to estimate the total number of validators that those nodes are responsible for.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, the data is less useful for understanding concentration. While it&rsquo;s helpful to know the concentration of nodes among geographies, to gauge the risk of non-finalization or even downtime leading to penalties and missed rewards, you want to know the concentration of validators not just nodes.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Using this node-level concentration data they apply a fixed weight to decide on a level of decentralization for a chain. While this binary approach is acceptable, a granular binning approach with an upper limit might be better. Using binning would allow us to negatively score validators located in countries that are under our maximum threshold, but still overly concentrated, rather than being binary.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Using this network-level data would be helpful for our scoring. For example, just because a relatively large percentage of the Lido protocol set of validators is located in country X is not reason enough to be concerned. We must also factor in the global network concentration as well, and only with both data points can we accurately gauge the risk. Over an infinite number of games, Lido protocol must contribute positively to the overall health of the network, as well as minimize its own internal concentration risk.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Observatory Zone no longer scores based on software versions, but this was a feature in their whitepaper. They would monitor the latest versions of software, particularly clients, and then penalize based on the magnitude of the version &ldquo;delay&rdquo;.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>The problem with version monitoring is that by punishing those who are using &ldquo;outdated&rdquo; versions you increase concentration risk.</span><span class="c2 c0">&nbsp;The upside is that in cases where the outdated client has a bug, the scoring system should push NO&#39;s to move to the newer version. In the inverse case, where the new version has a bug, the problem is only magnified by additional usage. It makes no sense to punish those with deliberate upgrade strategies that involve waiting until versions are battle tested.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Presumably, NO&#39;s are incentivized to move away from faulty outdated versions because they want to avoid loss of ETH. T</span><span>herefore, it&rsquo;s not necessary to use version tracking because the same incentive can be created only by scoring based on rewards, penalties, and slashing.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Overall, the approach taken by Observatory Zone is not highly useful to our problem</span><span class="c2 c0">. One takeaway should be that there can be a benefit to tracking network-level data in aggregate, which we also see from Rated Network.</span></p><h3 class="c6" id="h.3zie4vm5r34m"><span class="c3">Minimizing Risk</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">The L</span><span>ido </span><span class="c0">scorecard identifies the following risk factors; white-labeling, operator concentration, geographic concentration, infrastructure concentration, security and key risk, client concentration, malicious intent</span><span>,</span><span class="c2 c0">&nbsp;and governance risk.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Other risks exist beyond those mentioned, but these cover the bulk of the present risk for stakers.</span></p><h4 class="c33" id="h.oi7of5ooz0uc"><span>Internal Processes</span></h4><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Internal processes would include security</span><span>, </span><span class="c0">key management, change management, user access management, </span><span>failover/failback</span><span class="c0">&nbsp;processes</span><span>, </span><span>and access policies.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">To date, most slashing </span><span>has been the</span><span class="c0">&nbsp;result of poor processes, </span><span>particularly for failover and failback scenarios</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Failover can </span><span>maintain higher</span><span class="c0">&nbsp;uptime</span><span>&nbsp;- </span><span class="c0">a critical factor in the rewards that a validator earns. But failover</span><span>s </span><span class="c0">without sufficient failback </span><span>processes</span><span class="c0">&nbsp;can lead to slashing, as we&rsquo;ve seen in the </span><span class="c7 c22"><a class="c23" href="https://www.google.com/url?q=https://blog.lido.fi/loe-rocklogic-gmbh-slashing-incident/&amp;sa=D&amp;source=editors&amp;ust=1700278667380350&amp;usg=AOvVaw3Kq2lgZUTFbLQFmHv81X6N">case of </a></span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://blog.lido.fi/loe-rocklogic-gmbh-slashing-incident/&amp;sa=D&amp;source=editors&amp;ust=1700278667380772&amp;usg=AOvVaw0_Gvdrw099yerbf0JFlY7G">RockLogic</a></span><span class="c0">. </span><span>V</span><span class="c0">alidators were </span><span>taken offline</span><span class="c0">&nbsp;through a failover process and rest</span><span>ored elsewhere. Later, they attempted to failback to their original server, where they believed all keys had been cleared. However, the keys were unexpectedly re-imported, leading to </span><span class="c0">slashing offenses. This event </span><span>exemplifies</span><span class="c0">&nbsp;the importance of correct failover and failback</span><span>&nbsp;processes.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>The </span><span class="c0">ETH lost to slashing </span><span>was</span><span class="c0">&nbsp;orders of magnitude more than would have been lost to any downtime</span><span>&nbsp;from waiting for a bug fix to be implemented</span><span class="c0">. </span><span>S</span><span class="c0">uccessful failover and subsequent failback is preferable to downtime, but an unsuccessful failover and failback. A preference for safety ov</span><span>er liveness will ensure greater performance over time.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>S</span><span class="c0">ignificant diligence needs to be paid to the internal processes of </span><span>NO&#39;s</span><span class="c0">&nbsp;</span><span>to</span><span class="c2 c0">&nbsp;reduce risk at the Lido set level.</span></p><p class="c1"><span class="c2 c0"></span></p><h4 class="c33" id="h.vqqpfqtqo0x1"><span class="c26 c0">Hardware</span></h4><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>The diversity in individuals staking</span><span class="c0">&nbsp;is critical to the security of the network. The success and fairly widespread nature of home staking (sometimes referred to as solo st</span><span>aking)</span><span class="c0">&nbsp;proves that </span><span>individuals can run</span><span class="c2 c0">&nbsp;validators on local hardware, or cloud servers.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>I looked at 7 months of historic validator performance data from Rated, including only validators that had data for the full period. </span><span class="c0">The data shows that deposit addresses with only 1 validator have marginally better median uptime and correctness than Lido </span><span>NO&rsquo;s</span><span class="c0">. You could conclude from this that the hardware and infrastructure of an operator is irrelevant to core metrics </span><span>that</span><span class="c2 c0">&nbsp;underlie performance.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">However, according to interviews with large </span><span>NO&#39;s</span><span class="c0">, as the number of validators that an </span><span class="c0">operator runs increases the complexities increase superlinearly, to a point</span><span class="c0">. </span><span>One</span><span class="c0">&nbsp;cannot presume to run 1000 validators by simply replicating their hardware 1000 times. The additional scale adds problems around </span><span>security, </span><span class="c0">maintenance, downtime recovery</span><span>,</span><span class="c0">&nbsp;and management. Beyond this, </span><span>at scale</span><span class="c0">&nbsp;risk management requires diversification, adding further complexity when multiple clients may </span><span>be run simultaneously</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">According to NO&#39;s, network bandwidth can become a serious bottleneck as the number of validators increases. This bottleneck could explain some differences in performance when compared against solo stakers.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 332.00px;"><img alt="" src="images/image18.png" style="width: 624.00px; height: 332.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c0 c16">The above graph is a simplistic representation of the curve that can be expected between scale and complexity. No values are displayed, as I only intend to show the curve, with the precise number of validators where the step function occurs is dependent on the NO&#39;s decisions.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>At the scale of NO&rsquo;s insufficient</span><span class="c0">&nbsp;hardware</span><span>&nbsp;will cause </span><span class="c0">higher downtime, more missed attestations and block proposals</span><span>,</span><span class="c0">&nbsp;and therefore lower earnings.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>When examining the NO&rsquo;s data there is a relatively large dispersion in these performance metrics due to NO&rsquo;s different infrastructure, which we will discuss later.</span></p><h4 class="c33" id="h.jartej8o6sdy"><span class="c26 c0">Hosting vs On-Premises</span></h4><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Estimates show that</span><span class="c0">&nbsp;between </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://ethernodes.org/network-types&amp;sa=D&amp;source=editors&amp;ust=1700278667386852&amp;usg=AOvVaw0jxjznUj28YHKLhJCxr0N1">57%</a></span><span class="c0">&nbsp;and </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://monitoreth.io/validators&amp;sa=D&amp;source=editors&amp;ust=1700278667387445&amp;usg=AOvVaw1xtROuJlv7WPhYNZ54zs5Q">58%</a></span><span class="c0">&nbsp;of validators </span><span>are connected to nodes</span><span class="c0">&nbsp;run on hosting, cloud</span><span>,</span><span class="c0">&nbsp;or otherwise. This concentration </span><span>presents </span><span class="c0">a systemic risk</span><span>&nbsp;of mass </span><span class="c0">downtime and </span><span>the risk of slashing from a malicious actor</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Within </span><span>the Lido protocol, </span><span class="c0">a </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://app.hex.tech/8dedcd99-17f4-49d8-944e-4857a355b90a/app/3f7d6967-3ef6-4e69-8f7b-d02d903f045b/latest&amp;sa=D&amp;source=editors&amp;ust=1700278667388457&amp;usg=AOvVaw1JPnMU-GwVLqHhQ9-L0Ic0">less severe concentration</a></span><span>&nbsp;</span><span class="c0">exists, with</span><span>&nbsp;48.3</span><span class="c0">% of </span><span class="c0">validators</span><span class="c0">&nbsp;be</span><span>ing connected to nodes</span><span class="c0">&nbsp;run </span><span>on </span><span>shared hosting</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Much of the world</span><span>&rsquo;</span><span class="c2 c0">s hosting capability falls under the legal jurisdiction of the United States, creating a single point of failure. Similarly, there is a meaningful concentration of physical server farms in a handful of cities around the globe.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Lastly, greater security risks can exist on </span><span>shared</span><span class="c0">&nbsp;servers. With the largest Lido </span><span>NO&#39;s</span><span class="c0">&nbsp;being responsible for hundreds of millions of dollars worth of ETH, there is an enormous incentive for bad actors in hosting </span><span>companies</span><span class="c0">&nbsp;to take malicious action. While it would be incredibly hard to execute, data breaches occur at major providers.</span><span class="c0">&nbsp;This risk is particularly present when </span><span>an external signer is not used.</span></p><h4 class="c33" id="h.tebb30xhmu5n"><span class="c26 c0">Jurisdictional and geographical concentration</span></h4><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Much of the geographic risk </span><span>to Ethereum exists because of the</span><span class="c0">&nbsp;</span><span>concentrated</span><span class="c0">&nbsp;server location</span><span>s </span><span class="c0">of shared </span><span>servers, and the legal jurisdictions of hosts</span><span class="c0">. However, it&rsquo;s also important to consider the </span><span>same </span><span class="c0">concentration </span><span>among NO&rsquo;s</span><span class="c0">, regardless of whether they </span><span>use shared</span><span class="c0">&nbsp;</span><span>hosting</span><span class="c0">&nbsp;or </span><span class="c0">on-premises</span><span class="c0">&nbsp;</span><span>servers</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Across the Ethereum network, between </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://www.rated.network/overview?network%3Dmainnet%26timeWindow%3D30d%26rewardsMetric%3Daverage%26geoDistType%3Dall%26hostDistType%3Dall&amp;sa=D&amp;source=editors&amp;ust=1700278667391834&amp;usg=AOvVaw1TtgsUwiIXEtJs1RjRV_VD">33%</a></span><span class="c0">&nbsp;and </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://ethernodes.org/countries&amp;sa=D&amp;source=editors&amp;ust=1700278667392252&amp;usg=AOvVaw1Nj64wOMzPGLIQVL8qgC90">41%</a></span><span class="c0">&nbsp;of validators are estimated to be physically located on servers in the United States, with 14% to 19% in Germany. Given that ~40-50% of validators in each country are in Ashburn and Frankfurt respectively, it&rsquo;s highly likely that these two cities represent the bulk of AWS exposure globally and Hetzner</span><span>&rsquo;</span><span class="c0">s USA </span><span>exposure</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Data identifying the number of nodes for each hosting provider varies widely so it&rsquo;s not possible for us to reliably use this granularity of data for scoring. Notably, there is enormous variance in the estimations of AWS and Hetzner concentration.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Currently, </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://app.hex.tech/8dedcd99-17f4-49d8-944e-4857a355b90a/app/3f7d6967-3ef6-4e69-8f7b-d02d903f045b/latest&amp;sa=D&amp;source=editors&amp;ust=1700278667393500&amp;usg=AOvVaw3rF1cCqJIHmugKRvI64Lxr">data is self-reported by NO&rsquo;s</a></span><span class="c0">&nbsp;detailing their server locations </span><span>and </span><span class="c2 c0">jurisdictional dispersion. In the available data, primary server locations are significantly more diversified than the global average, with only 16% of primary servers located in the USA, but 15% in Germany.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Jurisdictionally, NO&rsquo;s are somewhat concentrated</span><span class="c0">, </span><span>with </span><span class="c0">~58% exposure to Europe</span><span>, </span><span class="c0">~28% </span><span>in the Americas</span><span class="c0">, with the remaining 14% across APAC. </span><span class="c2 c0">Jurisdictional risks exist when they lead to mass downtime across the network, with the possibility of an inactivity leak.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>For this risk to be managed NO&rsquo;s must be diversified to the network-wide concentration. </span><span>However, with no reliable data on the network-wide jurisdictions of validators, we must instead be particularly cautious and ensure a greater diversification of jurisdictions among NO&rsquo;s. </span><span>Therefore, it&rsquo;s sufficient to use only internal NO jurisdiction data for scoring.</span></p><h4 class="c33" id="h.kxw17amguh4g"><span class="c26 c0">Operator concentration</span></h4><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Currently, </span><span>there is a</span><span>&nbsp;soft cap such that a NO</span><span class="c0">&nbsp;</span><span>should be limited to</span><span class="c0">&nbsp;a 1%</span><span>&nbsp;allocation (via the Lido protocol) </span><span class="c0">of </span><span>the </span><span>total ETH in the Lido protocol</span><span class="c0">.</span><span class="c0">&nbsp;</span><span class="c2 c0">In my opinion, a limit on NO concentration should exist to reduce the financial impact on stakers in the case of an event and to reduce the control a single entity has over the network.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>We know that the magnitude of the financial impact under negative scenarios scales with the number of validators impacted; because slashing has a correlation penalty and inactivity leaks only occur during non-finality (when more than a third of the network is offline). Similarly, an entity&rsquo;s impact on the network is not </span><span>dependent</span><span class="c2 c0">&nbsp;only on the number of validators they operate using the Lido protocol, but the total number they operate.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For a NO concentration limit to &ldquo;reduce the financial impact&rdquo; and &ldquo;control a single entity has&rdquo; we must look at the total validators a NO controls, not their percentage of Lido&rsquo;s ETH.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">If the current 1% cap is included in a scoring system as a hard limit it would necessarily override the other scoring criteria. The result is to attempt to reduce internal NO concentration, but without considering the impact that this has on other risks. Hence, to utilize a scoring system for ETH allocation it will be necessary to adjust the limit.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>To manage the risks of financial impact and network control we must factor in the total number of validators a NO controls.</span><span>&nbsp;However, this could be through a scoring system that punishes an </span><span>entity&#39;s</span><span>&nbsp;network concentration, rather than a low discrete limit on the percentage of Lido ETH a NO controls</span><span>. The level of concentration at which it would impact a score is highly subjective and should be decided by the DAO. </span><span>But the critical difference is that this level is relative to the total number of validators a NO controls across the network.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Both the concentration of an operator network-wide and their concentration of Lido stake are important. Considering both metrics is critical for accurate risk scoring.</span></p><h4 class="c33" id="h.zifpe0lz3clg"><span class="c26 c0">Ensuring a Profitable Business Opportunity</span></h4><p class="c5"><span>NO&rsquo;s</span><span class="c0">&nbsp;</span><span>face</span><span class="c0">&nbsp;high sunk costs</span><span>&nbsp;when starting their business, particularly if they choose to run on-premises. </span><span class="c0">Even those hosting will need to invest considerable resources in internal software for management, security audits</span><span>,</span><span class="c0">&nbsp;and staffing. This significant upfront investment makes it challenging for </span><span>NO&#39;s</span><span class="c2 c0">&nbsp;to be immediately profitable with a relatively low number of validators.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 332.00px;"><img alt="" src="images/image22.png" style="width: 624.00px; height: 332.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c41">The above graph is a simplistic interpretation of the NO&rsquo;s unit cost, where running a small number of validators is cheap per unit, then requires high fixed and sunk cost investments, before becoming highly profitable per unit at scale.</span><span class="c16 c0">&nbsp;This is based on interviews with NO&rsquo;s, who maintained that cost decreases at scale, but operations at a very large scale can start to become more costly again.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>T</span><span class="c0">here</span><span>fore, it&rsquo;s expected that new NO&rsquo;s will require a high minimum number of validators if they are to operate similar infrastructure to existing NO&rsquo;s</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>T</span><span class="c0">hese economics </span><span>dictate that the percentage of monthly revenue remaining</span><span class="c0">&nbsp;to invest in </span><span>improvements</span><span class="c0">&nbsp;</span><span>is </span><span class="c0">correlated to the NO</span><span>&rsquo;s </span><span class="c2 c0">number of validators.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">We&rsquo;ve already established that running high-quality infrastructure is expensive by global standards. Curr</span><span>ently, NO&rsquo;s are well-funded entities that can afford the sunk costs to achieve high-quality infrastructure from the start. As the NO set increases we can expect that the resources of new NO&rsquo;s will reduce, particularly with significant additional size. Over the long run, NO&rsquo;s</span><span class="c0">&nbsp;should act as rational profit maximizers</span><span>. So, NO&rsquo;s</span><span class="c0">&nbsp;with </span><span>fewer</span><span class="c0">&nbsp;validators are likely to run </span><span>lower-quality</span><span class="c0">&nbsp;setups</span><span class="c0">. Similarly, as an operator loses validators there should be a superlinear degradation in their setup quality</span><span>&nbsp;to maintain profitability</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Hence, a future scoring system should consider the economics of NO&rsquo;s and ensure that the distribution and velocity of changes in the distribution do not negatively impact the infrastructure of the set.</span></p><p class="c1"><span class="c2 c0"></span></p><h3 class="c6" id="h.wazfhla979tv"><span class="c0">Performance and </span><span>Rewards</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Stakers decisions are influenced by the APR that they will earn but </span><span class="c0">what&rsquo;s not clear is the exact curve that explains the relationship between AP</span><span>R</span><span class="c0">&nbsp;and Lido stake</span><span class="c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Lido offers a unique advantage </span><span class="c2 c0">through the utility of stETH. While centralized competitors typically do not offer a liquid token and DeFi competitors liquid tokens have orders of magnitude lower utility due to less inclusion in DeFi protocols. When we consider how users are using stETH, we can see that the majority do not actively use their stETH. Among the minority that is they are overwhelmingly using it to stake in lending protocols, earning additional rewards for providing liquidity. These actions suggest that for a subset of Lido stakers the total APR that they can earn is a driving factor, given their decision to take on incremental risk to earn higher net rewards.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For a different subset of global ETH stakers they choose CEX&rsquo;s, where they are earning significantly lower rewards than with Lido, regardless of whether they subsequently re-stake stETH. Clearly, for these users, APR is not the driving factor in their decision.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Having spoken to many of these users and their providers, I believe that their driving factor is compliance. Much of the ETH staked with CEX&rsquo;s is from institutions whose compliance teams may have only approved specific counterparties, often with the requirement of no co-mingling of funds with non-KYC&rsquo;d individuals.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, my understanding is that much of this ETH would be unable to be staked in Lido currently and so it&rsquo;s not as relevant to our analysis as protocol competitors. Here, we want to look primarily at how APY drives decision-making among those who could use Lido.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 330.67px;"><img alt="" src="images/image1.png" style="width: 624.00px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">According to data from Rated</span><span>&nbsp;</span><span class="c0">for the latest </span><span>90 days</span><span class="c0">, Lido has the highest </span><span>after-fee</span><span class="c2 c0">&nbsp;APY among the largest six pools.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">In contra</span><span>s</span><span class="c0">t, when we look at the growth of each provider we see this over the past </span><span>365 days</span><span class="c2 c0">&nbsp;of data:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 330.67px;"><img alt="" src="images/image26.png" style="width: 624.00px; height: 330.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c16 c0">This graph looks at the relative (current validators / previous validators) growth in the number of validators by pool.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Clearly, despite RocketPool having the lowest APY after fees among the pools, it&rsquo;s had the highest </span><span>relative percentage</span><span class="c2 c0">&nbsp;growth.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">Using only percentage growth in validators doesn&rsquo;t tell the full story</span><span>. In these 365 days, RocketPool had a pre-existing queue which they were able to begin to stake. They also transitioned to allow 8 ETH bonded pools, significantly increasing their capacity</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>When we look at the absolute growth in the number of validators over the period we can see that Lido has </span><span class="c7">added more validators than the current size of any of the other pools</span><span class="c2 c0">.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Lido is growing significantly quicker than any other single pool and this may be influenced by the APY that stakers can earn. The correlation between these factors is weakly positive, but I did not include the rewards that would be earned if you re-utilized your stETH in another DeFi protocol. When considering this, the correlation is much stronger, as would be expected.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">A plausible explanation is that for those users for whom APR is the driving factor, Lido is the clear choice because of the far superior potential net earnings. This alone could be responsible for much of the growth, though it&rsquo;s hard to isolate any specific factor.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c0">The takeaway from this data</span><span class="c2 c0">&nbsp;is that APY plays an important role in Lido&rsquo;s continued growth, but it&rsquo;s not the only factor. Given Lido&rsquo;s position as the highest earning provider, additional increases in APY are likely to impact growth relatively less than for competitors. However, we can presume there is some relationship between the two whereby at a low enough APY Lido would lose users, and at a high enough APY growth could be even greater.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>When thinking about pursuing additional APY we must weigh the risk against the opportunity cost and this will depend on how the extra APY is intended to be earned. This chasing of </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://blog.staked.us/blog/eth2-post-mortem&amp;sa=D&amp;source=editors&amp;ust=1700278667402945&amp;usg=AOvVaw34Je5vq9TUzeX_CPgmCqrZ">attestation performance at the expense of reliability</a></span><span class="c2 c0">&nbsp;resulted in a significant slashing event for Staked.us.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>If implemented as a metric in a scoring system we must think about how APY could encourage NO&#39;s to cut corners in pursuit of higher earnings. Yet, we must balance this against the knowledge that it&rsquo;s a key factor for users. Later, we&rsquo;ll discuss whether underlying performance metrics are a sufficient proxy for APY or whether we should include it in scoring.</span></p><h1 class="c19" id="h.yrrl54f9hoqd"><span class="c7 c10 c18">&lsquo;On-Chain&rsquo; Performance Data</span></h1><p class="c5"><span class="c2 c0">The following NO on-chain performance data is entirely sourced from Rated Network, to ensure consistency when comparing metrics for usage. The data looks at 7 months of results. We also consider the latest 50,400 blocks when looking at Relay data and dig deeper into the payloads from the Flashbots relay.</span></p><h2 class="c11" id="h.87ykjajkw0ek"><span class="c18 c7 c10">Attestations</span></h2><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">Attestations include three different &ldquo;votes&rdquo; - the source, head, and target of the chain. In terms of importance, the source is most important, followed by the target and then the head.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Rewards:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 134.67px;"><img alt="" src="images/image25.png" style="width: 624.00px; height: 134.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Penalties:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 298.67px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 298.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Without a correct source vote, you incur the maximum penalty and the greatest missed rewards. While with only a correct source, but an incorrect target, you will still earn a net positive earnings after the penalty. Lastly, with a correct source and target, but an incorrect head, you will receive no penalty and miss out on a small amount of rewards.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Given that each &ldquo;vote&rdquo; relies on the previous &ldquo;stage&rdquo; to be correct, we can say that the source vote is the most important.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Also, we know that the head vote is significantly less important than the target, with the target being worth 3.7</span><span>x </span><span class="c2 c0">more in net earnings (missed rewards and penalties) for correctness relative to the head vote.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, I don&rsquo;t believe that it&rsquo;s sufficient to only measure average correctness across votes when it&rsquo;s evident that correctness in one vote is more important than in another. Instead, we will need to separate them into individual metrics and score each differently.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Again, it could be argued that this data is accounted for in the average rewards, missed rewards, and penalties data. However, these metrics are directly influenced by uptime. Uptime is critical, but using only &ldquo;higher level&rdquo; metrics consistently throughout the scoring will result in uptime accidentally being a dominant factor because it would influence all of these higher-level data points directly. The same is true for other &lsquo;hidden&rsquo; factors that are present throughout many high-level metrics.</span></p><h3 class="c6" id="h.os0t32vuvv7q"><span class="c3">Average source correctness</span></h3><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">Average source correctness is calculated as the number of correct source votes made divided by the number of votes made by the operator in the period.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 309.33px;"><img alt="" src="images/image9.png" style="width: 624.00px; height: 309.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Variance &amp; Standard Deviation: The standard deviation value we calculated for the entire dataset is approximately 0.0721%. Such a low standard deviation suggests that average source correctness doesn&rsquo;t have a wide variation.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Skewness: The skewness value is &minus;2.94, which is notably negative. This indicates a pronounced left-skewed distribution, which we can see in the graph (most data is on the right). This suggests that while the majority of scores are close to the upper limit (close to 100% correct), there are a few entities with significantly lower scores in a given month. These underperforming entities can be seen as serious exceptions rather than the norm, given the pronounced skewness.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image20.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When we look at each operator, grouped by backward-looking 30-day &lsquo;months&rsquo;, we can see a significant disparity between the bulk of NO&#39;s around the mean, and those performing worse.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Most importantly we should note that the NO&#39;s that are far below the average tend to always be below the average, rather than fluctuating above and below. Therefore, we can have a much higher degree of confidence when choosing to score NO&#39;s performing poorly.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Given the strong concentration around the mean, it&rsquo;s not suitable to score NO&#39;s against a curve because we want to avoid punishing NO&#39;s whose recent performance is only a little below the mean. Again, the easiest approach here would be to use binning and to negatively score only the lowest-scoring bins. Alternatively, we could look to mark a floating percentage below the average based on the level of variance in the previous month.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image24.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When we plot only the best and worst three NO&#39;s against the average it becomes clear that the difference is very notable and fairly consistent over multiple months. Specifically, we see that the best NO&#39;s are highly consistent with less variance month-to-month compared to the lower-performing NO&#39;s.</span></p><p class="c1"><span class="c4"></span></p><h3 class="c6" id="h.2sxl8wfpfl15"><span class="c3">Average target correctness</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Average target correctness has quite a different distribution to average source correction. </span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 309.33px;"><img alt="" src="images/image21.png" style="width: 624.00px; height: 309.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We see a much wider distribution of values, with higher standard deviation. Of course, the STD is still quite small, 0.14% around the mean of 99.74%.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Variance &amp; Standard Deviation: Given the scale of the values in the dataset (which are close to 1), this standard deviation is relatively low, though slightly higher than the previous dataset.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Implication: A low standard deviation suggests that the average target correctness for the NO&rsquo;s are fairly consistent. There isn&#39;t a wide variation in scores, meaning that most NO&rsquo;s have average target correctness that are close to each other. However, the slightly higher value compared to the source correctness indicates a bit more variability among NO&rsquo;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Skewness: The skewness is &minus;0.8999, which is negative, indicating a left-skewed distribution.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Implication: Similar to the source correctness, this left skewness suggests that while many entities have scores that are close to the upper limit (close to 1), there are a few NO&rsquo;s with significantly lower scores. These underperformers can be seen as exceptions rather than the norm.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">In summary, average target correctness exhibits characteristics similar to the source correctness dataset, with a bit more variability in performance. Most NO&rsquo;s have closely packed results around the upper end, but there are a few NO&rsquo;s that are notably underperforming.</span></p><p class="c1"><span class="c4"></span></p><h3 class="c6" id="h.x09kfofm9q3i"><span class="c3">Average head correctness</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 309.33px;"><img alt="" src="images/image31.png" style="width: 624.00px; height: 309.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Variance &amp; Standard Deviation: The standard deviation is approximately 1.208%. Given the scale of the values in the dataset (which are close to 1), this standard deviation indicates a moderate level of variability in the scores.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Implication: A moderate standard deviation suggests that there&#39;s some variation among NO&rsquo;s. This means that while many entities might have scores close to each other, there are entities that diverge from the average, both on the higher and lower ends.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Skewness: The skewness is &minus;3.5637, which is notably negative, indicating a pronounced left-skewed distribution. This pronounced left skewness suggests that many NO&rsquo;s have scores that are close to the upper limit (close to 1), but there are some significantly lower scores.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">In summary, head correctness shows a broader range compared to the target and source correctness datasets. The pronounced left skewness and high kurtosis hint at a few NO&rsquo;s that might be outliers in terms of their performance. These outliers, especially the ones on the lower end, can be of particular interest as they diverge significantly from the majority.</span></p><p class="c1"><span class="c4"></span></p><h3 class="c6" id="h.vk7vmvad99dy"><span class="c3">How attestation correctness impacts earnings</span></h3><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">We can see that some patterns emerge from looking at the correctness of NO&#39;s by each of the votes. However, for this to be a useful metric to score NO&#39;s with it needs to tell a story about an operator being more risky to the set, or lowering the earnings.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image13.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">What we can see from the data is that there is one clear outlier, with another operator frequently below the mean, but returning to a value close to the mean in the most recent month.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The standard deviation is approximately 0.36%. So, this lowest-scoring operator with a mean rewards capture of 97.54% is ~4.41 standard deviations below the NO mean of 99.13%.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">While it&rsquo;s certainly possible to rank NO&#39;s based on this data, we need to think about what the variance between NO&#39;s attestation rewards captured means.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>In the very worst case, we&rsquo;re looking at capturing 96% of the rewards. If we just incorrectly presume that the attestation rewards are the only rewards possible, you can </span><span>think about capturing 96% of the ~4.5% APY on Ethereum validators currently. So, instead of earning 4.5%, you&rsquo;d earn 4.32%</span><span class="c2 c0">. This calculation does not consider the impact of penalties, which would lower the APY, but not drastically. Some difference exists here, but it&rsquo;s relatively small and less than the difference in after-fee earnings between Lido and Coinbase.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The standard deviation is approximately 0.4574%. In APY terms, being one standard deviation worse than the mean operator would mean earning ~ 4.48% instead of 4.5% APY.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We might consider whether the correctness of votes can tell us something about risk.</span></p><p class="c1"><span class="c2 c0"></span></p><h3 class="c6" id="h.sqx9jnt5pefn"><span class="c3">Vote correctness and risk</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">To assess the risk that may be represented by lower correctness, we need to first think about how a validator will typically get votes incorrect or delayed.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>The most </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://medium.com/offchainlabs/validator-performance-tracking-a2ea9ab44b3a&amp;sa=D&amp;source=editors&amp;ust=1700278667411443&amp;usg=AOvVaw2f2Kbq-vMKgYyyidP6Ix1O">common reason for an incorrect source vote</a></span><span class="c2 c0">&nbsp;is &ldquo;downtime in bandwidth or other networking issues&rdquo;.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Incorrect target votes, with a correct source vote, are typically the result of delay. Either in the form of network delay, whereby the block was proposed late and so broadly validators are incorrectly voting for the target, or because of our peering issues. With some blocks arriving later than others, the difference in an NO&#39;s bandwidth can make the difference between a correct and an incorrect target vote.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Lastly, the head vote is far more frequently wrong than the target or source. Typically, this is because of the same delayed block issues, particularly when attesting in the first slot of an epoch.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Sometimes it&rsquo;s extremely hard to be correct. When a block is extremely late, but not so late as to be missed by the next proposer, you&rsquo;ll see a lower level of correctness across the network. However, it&rsquo;s evident by persistent differences in correctness among NO&#39;s that much of the variance is in fact in the control of the operator.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">That variance seems to largely be a result of differences in setup that cause some NO&#39;s to more reliably turn relatively delayed blocks into correct votes, while others vote incorrectly.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For example, an operator with a higher bandwidth and a greater monthly data transfer limit might choose to connect to more peers per validator. As a result, they might get these relatively delayed blocks marginally faster than another operator, allowing them to make a correct vote rather than one that&rsquo;s incorrect.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Or, an operator using slower hardware might find that even though they receive at the same time, they are unable to turn around a vote quickly enough.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">However, it&rsquo;s not only bandwidth and hardware that can have an impact. Perhaps you could be using Vouch with multiple beacon nodes, with different consensus clients, and you&rsquo;re specifically waiting for multiple clients to give the same answer before you attest. This seems very unlikely, but it exemplifies how an operator could be taking the &lsquo;right&rsquo; actions to minimize risk and result in lower vote correctness.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">A more realistic example might be an operator hosting multiple nodes in different geographies, but the one on the same server as Vouch is offline. In this case, Vouch would be forced to wait for a response from the nodes abroad before it can attest, which would add a meaningful delay when a block is already delivered fairly late.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">So, we should be careful with the weighting of correctness as some proxy for the quality of an NO&#39;s setup. It gives us some information, particularly when NO&#39;s are regularly performing below the mean in all votes. Overall, I believe this is a strong metric for scoring, but as you&rsquo;ll see with most of the data available, we still must be careful when weighing these in a scoring algorithm.</span></p><p class="c1"><span class="c4"></span></p><h3 class="c6" id="h.wvtbes5opq6t"><span class="c3">Average inclusion delay</span></h3><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">Average inclusion delay is the mean of the distance between the slot where a validator&rsquo;s attestation is expected by the network and the slot where the attestation is included on-chain.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Variance &amp; Standard Deviation: A low standard deviation relative to its mean suggests that most inclusion delays are close to the average, but, as indicated by the skewness and kurtosis, there are some extreme values.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Skewness &amp; Kurtosis: High positive skewness and kurtosis suggest that there are extreme values that might be outliers.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Range: The delay varies from 0 to 2.61 slots. There are outliers in terms of incorrect data (zero delay isn&rsquo;t possible so this would need to be removed from the data, while 2.61 slots is extremely delayed).</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Relevance: Delays in inclusion can be a sign of poor operation and because delay can result in penalties and missed rewards, is a factor for evaluating the risk of those events. Hence, it&rsquo;s not sufficient to only look at historical rewards and penalties alone, as we must factor in future risk.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Transformation: Given that inclusion delay is easy to understand, we should try to retain that characteristic. We can bin or categorize the values. For instance, we can create categories like &#39;low delay&#39;, &#39;medium delay&#39;, &#39;high delay&#39;, and &#39;very high delay&#39; based on quantiles or predefined thresholds. This approach retains the impact of outliers as well, and since our goal should primarily be to punish poor outliers, maintaining outliers is critical.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Handling Strategy: Values in the &#39;very high delay&#39; category can be heavily penalized in the scoring system.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">As you would expect, inclusion delay is fairly similar to the correctness data, but with a slightly greater dispersion of outlying NO&#39;s above (worse than) the mean.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Notably, Rated chooses to ignore inclusion delay for scoring, instead having it feed in based on whether the delay results in missed rewards and penalties. As mentioned earlier, the magnitude of the delay holds important information regardless of whether the delay was so extensive as to result in missed rewards and penalties.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">With heavy skew and kurtosis, what we see is that the bulk of all validations happen within a small range of delays. It doesn&rsquo;t make sense to penalize NO&#39;s with greater than usual average inclusion delay when that delay is still fairly close to the mean.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Alone this data is not overly helpful, but when paired with the correctness rates for different votes the inclusion delay can help tell us why a vote is incorrect. </span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When we see excessive average inclusion delay we can be more confident that incorrect votes are as a result of the NO&#39;s setup leading to late attestations out-of-slot. This is because an incorrect vote in the correct slot would suggest that the NO&#39;s setup is operating well enough to receive data, parse it, and return an attestation on time, though incorrectly. That could be a result of client failure for example.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">A delayed and incorrect attestation is more likely to be a result of a delay in receiving data and outputting an attestation, which is acceptable periodically, but less than ideal as a pattern.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This data is well-suited to be used for identifying significant outliers via a binning approach.</span></p><h3 class="c6" id="h.y72q4clc29a4"><span class="c3">Average uptime</span></h3><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">Uptime has some of the same patterns that we&rsquo;ve seen so far, but noticeably the NO&#39;s performing below the mean are not necessarily the same as those with below-average correctness. However, they do more closely match those with higher inclusion delay, another signal of potential setup issues, particularly around connection quality.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Most notably, the same operator has had the poorest performance in all metrics so far. </span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Uptime is specifically measured as the number of epochs a validator&rsquo;s attestation was included on-chain divided by the number of epochs that the validator is active, aggregated across the NO&#39;s set.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">So, it should have little correlation to correctness, which only looks at attestations that were made. Given that this same operator is last in all categories, as well as uptime, this hints at systemic issues.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image8.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The standard deviation is approximately 0.2%. So, this operator with a mean uptime of 99.21% is ~4.42 standard deviations below the NO mean of 99.87%.<br></span></p><p class="c5"><span class="c2 c0">The logic for using uptime in a scoring system is simple - you cannot maintain sufficient earnings if your uptime results in significantly more missed attestations and block proposals than other NO&#39;s. The metrics that we&rsquo;ve considered so far only look at events that have happened. If we do this, an operator could be offline, then make a single correct attestation and score 100%. This is not good, so we do need to include some proxy for uptime, or at least a factor that looks at a broader set of factors.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">However, scoring on uptime could incentivize NO&#39;s not to update regularly, or to rush their updates, such as to minimize downtime. Later, we&rsquo;ll look at if there&rsquo;s another proxy that we can use.</span></p><h2 class="c11" id="h.ol4igvh6ga90"><span class="c18 c7 c10">Block Proposals</span></h2><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">We expect that ~1/8th of our rewards should come from block proposals and the associated rewards. For this period of data, it&rsquo;s a little bit lower, with attestations representing more than 7/8ths of the earnings, likely because of relatively low demand for blockspace.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Yet when we look at relatively shorter periods you&rsquo;ll notice that there can be meaningful differences in APY among NO&#39;s with similar attestation performance. The reason is because of the huge variance in EL rewards that can come with proposing a block. This effect is still noticeable even across NO&#39;s with thousands of validators.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The majority of this variance is due to luck. NO&#39;s can take steps to maximize their EL rewards by delaying proposals to include more transactions and using relays to re-order transactions more profitably. However, the bulk of the variance in rewards between blocks is out of the NO&#39;s control.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, it&rsquo;s evident that the actual rewards earned as a block proposer are not applicable for scoring NO&#39;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">However, because these blocks contribute 1/8th of our earnings over infinite epochs and can contribute an order of magnitude more over years, they are critical.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image14.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When looking at the percentage of block proposals missed we can see some dispersion among NO&#39;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The standard deviation is approximately 0.5015. This indicates a moderate to high level of variability, suggesting that there&#39;s a notable variation in the missed proposals among NO&#39;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The skewness value is 3.1409, which is positive and indicates a pronounced right-skewed distribution. This pronounced right skewness suggests that many NO&#39;s are close to the lower limit (zero), but there are some NO&#39;s with significantly higher missed proposals. These NO&#39;s with higher missed proposals can be seen as exceptions rather than the norm.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Notably, there is some consistency in where NO&#39;s rank via a quintile binning approach, which could make this a suitable metric to score NO&#39;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image6.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The percentage of blocks that are empty is less ideal for scoring because smaller NO&#39;s can frequently have zero empty blocks in a period only because they propose few blocks. Therefore, the rarity of these events makes it an insufficient metric, when used alone, for usage in scoring and this will likely be the case as Lido onboards a greater number of NO&#39;s, leading to higher variance in the number of block proposals per operator in a given period.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image7.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When looking at the actual block rewards earned per proposal we can see a very tight grouping. Instinctively, I would assume that any metric involving block rewards would be a poor choice due to the randomness of rewards.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">However, what we see is that there is a fairly low standard deviation and high consistency of ranking position in NO&#39;s. The difference between NO&#39;s is small and so if used in a scoring system this metric needs to be scored delicately, either by only punishing significant outliers based on magnitude or consistency of rank, or by punishing only very lightly.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Overall, although this isn&rsquo;t a perfect metric because there is some randomness when looked at over a longer period due to the consistency of rankings this is a good choice for inclusion in scoring. If used in conjunction with the percentage of missed blocks, and potentially empty blocks even, this could give a much stronger indication of an NO&#39;s proposal effectiveness. Whereas when used as a standalone metric it&rsquo;s weaker and therefore needs to be scored delicately, as we discussed previously.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image17.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Missed block rewards here use approach 1 from Rated, the average of recent blocks.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Looking at missed block rewards there is a huge variance. This metric has the potential to be skewed by being unlucky and simply missing a specific block that was worth tens of ETH. You could argue that this is outside of the NO&#39;s control because they cannot dictate the magnitude of rewards and were simply offline at the time.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The counterargument is that despite this, it&rsquo;s important to track because of the potential magnitude of rewards, missing a block can be either a non-issue or terrible. So, that makes it even more important to ensure that you miss as few blocks as possible and make efforts to keep validators online.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When compared to scoring on the percentage of missed blocks, the reward-based metric adds only information about the financial impact. The core problem is the missed proposal. Given that this financial impact is out of the NO&#39;s control this counterargument is fairly weak and hence it doesn&rsquo;t seem appropriate to score based on this metric.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The takeaway from all of the proposal effectiveness data is that no single metric is sufficient alone. But when combined even weaker (but still usable) metrics like empty blocks can become useful if, for example, we see that a single operator has an abnormal propensity for empty blocks alongside low rewards per block and higher-than-average missed proposals. We need to combine metrics to get a higher level of confidence in scoring proposal effectiveness because in isolation each metric has flaws. Combined, I believe that they have the potential to be a very strong part of a scoring system.</span></p><p class="c1"><span class="c4"></span></p><h2 class="c11" id="h.ze9zq81m29j5"><span class="c18 c7 c10">Slashing</span></h2><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">Existing validator scoring systems do not typically take into account the slashes incurred. Slashing is the harshest penalty that a validator can receive. It can happen because of:</span></p><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_5f16krkcz2yy-0 start" start="1"><li class="c5 c14 li-bullet-0"><span class="c2 c0">Making two differing attestations for the same target checkpoint.</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Making an attestation whose source and target votes &quot;surround&quot; those in another attestation from the same validator.</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Proposing more than one distinct block at the same height.</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Attesting to different head blocks, with the same source and target checkpoints.</span></li></ol><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">All of these slashable behaviors relate to &quot;equivocation&quot;, which is when a validator contradicts something it previously advertised to the network. So far, all slashes incurred by validators have resulted in the minimum penalty because the incidents were isolated and therefore had no correlation penalty applied. As a result, the validators were slashed for the minimum amount, which is currently set to 1 ETH.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">While slashing is the harshest penalty, for it to be financially painful to Lido it would need to occur simultaneously to a large percentage of validators to meaningfully impact APY.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For example, RockLogic recently incurred slashing penalties on 11 validators. The loss totalled 13.46 ETH. Currently, RockLogic is running 5,789 validators for Lido, earning 4.21% APY based on the 30-day backwards-looking APY. Extrapolated out to a year, they would generate &nbsp;7,799 ETH in rewards. Therefore, the total loss to this slashing event is only 0.17% of the rewards they would earn. Said another way, net they would earn 4.20% instead of 4.21% for the year.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This makes little difference financially to their performance. We see a significantly greater difference in rewards between NO&rsquo;s based on their attestation correctness rate and missed block proposals than we see from this slashing event.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This isn&rsquo;t to say that slashing isn&rsquo;t important and potentially far more harmful. This event was particularly isolated, with only 11 validators being slashed from a 500 validator cluster. An event ~50x the magnitude (the entire cluster) would be far more detrimental, taking APY down to 3.85%.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">In this case, RockLogic was able to limit the impact by acting somewhat quickly. So, we need to decide how to evaluate slashing.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">On one hand, small events like this have very limited financial impact and therefore you could argue that they should only have a relatively small impact on scoring. Perhaps this could be done by simply factoring the lost ETH into the total attestation rewards calculations and using the net number to try to score.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">On the other hand, it was fortunate that the extent of this event was contained. Having slashing of any kind is extremely rare, and so this gives us some information as to how well the operator is performing their duties more broadly. Given that other NO&#39;s have not been slashed, this could signal that any NO&#39;s getting slashed are not performing their services sufficiently.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Deciding which is the right approach is highly subjective and so I&rsquo;d suggest that the Lido DAO community needs to decide how to handle these events in scoring.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">My personal belief is that because of the vast number of validators each operator is running, any slashing event has the potential to impact many hundreds, if not thousands, of validators depending on how they cluster. Therefore, we must look at these events in terms of what could have happened, not only what did. Given the rarity of slashing and the relative ease of preventing it, my opinion is that NO&#39;s who are slashed must be scored far more harshly than the financial impact alone.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">By not doing so, you create a scoring system that incentives NO&#39;s to maximize only for financial performance, knowing that isolated slashing incidents will only marginally impact APY. This approach encourages cutting corners and can lead to an accumulation of risk.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, although it&rsquo;s not reflected directly in APY, I believe that because of the rarity of slashing in the data, this metric has the potential to be used harshly in scoring NO&#39;s.</span></p><p class="c1"><span class="c4"></span></p><h2 class="c11" id="h.jawyqqsbvh7g"><span class="c18 c7 c10">Correlation of factors</span></h2><p class="c5"><span>I</span><span class="c2 c0">f we look at the on-chain data that we&rsquo;ve reviewed so far, we can see that certain NO&rsquo;s consistently fall below the mean on the large majority of metrics. I don&rsquo;t believe that this is an anomaly. There can be some overlap in metrics, for example, uptime will impact rewards. However, I&rsquo;ve made an effort to use metrics that are isolated from other factors as much as possible by for example looking at the correctness of attestations, rewards per block proposed, and inclusion delay on attestations made. Therefore, there&rsquo;s a very limited correlation between factors.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Yet, what we see is that </span><span class="c7">for the lower-ranked NO&#39;s </span><span>(bottom decile)</span><span>&nbsp;their presence in the bottom decile for one metric is highly predictive of their presence for another. There is an underlying factor that correlates - the NO themselves. The infrastructure, processes, and decisions are constant across all metrics, and this appears to be the common denominator that&rsquo;s influencing this correlation for the poorest-ranking NO&rsquo;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When creating a scoring system it would be worthwhile to consider looking at rank position, rather than only scoring based on each metric individually. If an operator is last in a high percentage of the tracked metrics that gives us additional information beyond only looking at their aggregate score by say scoring each metric equally and taking an average.</span></p><p class="c1"><span class="c2 c0"></span></p><h2 class="c11" id="h.m214tcxp1b6c"><span class="c18 c7 c10">Miner extractable value (MEV)</span></h2><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">Over the last 30 days, MEV has generated surplus earnings above vanilla blocks of 5.6x the value of the vanilla block. The difference between vanilla and relayed blocks is huge and this can help to explain much of the variability in total CL + EL earnings between validators with similar attestation effectiveness.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 264.00px;"><img alt="" src="images/image28.png" style="width: 624.00px; height: 264.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We have applied the Interquartile Range (IQR) to the data to remove the values in the upper quartile, for the sake of making the graph more visually useful. Here, we look at the fees that were paid to NO&#39;s by builders, over the priority fees (tips) for the block.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We can see strong dispersion in results and most importantly, there is little consistency in the ranking of NO&#39;s across months. This inconsistency is due to the huge variability in blocks. One block can have far better permutations for MEV extraction than another and those permutations are out of the control of the operator. What is in the NO&#39;s control is whether they choose to use mev-boost, which relays they use (to an extent, depending on their server location vs relay server locations), and which bids from builders they choose to accept.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, while the MEV per block is not a helpful metric because of the large randomness, we might be able to calculate how much MEV was missed. The logic here is that we don&rsquo;t care how much MEV an operator earns in a period, or per block. What we care about is how much they leave on the table, because our goal should be to maximize earnings within the bounds of acceptable practices, which should be decided by Lido DAO.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">From Rated:<br><br>&ldquo;There are two main on-chain patterns in which we have observed value transfers between a block builder and a validator; (a) one that involves the end_tx as parametrized in the table above, and (b) one in which the value transfer happens exclusively via the fee_recipient.&rdquo;</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When the value is transferred directly to the validator by setting their address as the fee_recipient, tracking the MEV is more challenging and hence it&rsquo;s not included in the Rated data. They do not track this because it&rsquo;s hard to identify specifically which block build was chosen by the validator. Therefore, you cannot easily separate MEV from the priority fees.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">In the above data, we simply look at cases where the fee_recipient is set to the builder address and there is end_tx that is more than the priority_fees.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">However, for our case, we do not need to know exactly what was the MEV for a block and what was priority fees. What we care about is what could have reasonably been earned by the validator for a given block, and then aggregate that data across NO&#39;s over time. This calculation will give us some approximation of their MEV and tip effectiveness, or the percentage of potential MEV and tips that they earned.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">To calculate this we will need to total the priority fees and MEV that an operator earns for the period. This should be highly accurate, because although we can only decipher the magnitude of MEV separately to priority fees in 90-95% of blocks, in almost all cases we can see the total.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Then, we need to know what builders had bid for each of those same blocks and calculate the difference between those two values, which is the &ldquo;missed earnings&rdquo;. We can express this as a percentage of the potential maximum to show the NO&#39;s effectiveness at capturing these earnings.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>An interesting </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://arxiv.org/pdf/2305.09032.pdf&amp;sa=D&amp;source=editors&amp;ust=1700278667425495&amp;usg=AOvVaw3z3AtO2-eijPD8k__CgOg2">paper was released in May</a></span><span class="c2 c0">&nbsp;by members of the Ethereum Foundation, looking at the &lsquo;time value&rsquo; of proposers waiting to propose a block. They concluded that &ldquo;timing games are indeed worth playing for block proposers&rdquo; because they enable the capture of additional MEV by delaying block proposals. Yet they believe that most &ldquo;delayed block proposals are primarily due to latency in the block signing process, rather than a conscious strategy to maximize profits&rdquo;. Talking to NO&#39;s and Lido team members, much of this &ldquo;missed MEV&rsquo; is because attempts to collect it have resulted in increased missed blocks so it may be more challenging to capture than the paper concludes.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The authors believe that there is a lack of maximal MEV capture by proposers currently, either because of a &ldquo;lack of common knowledge&rdquo; or due to &ldquo;existing social norms&rdquo;. Notably, they conclude that these are not &ldquo;sustainable safeguards for maintaining economic fairness&rdquo; and that the blockchain will need to adapt, rather than assuming participants will maintain this behavior.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">My data to replicate this paper for Lido NO&rsquo;s shows that there is a significant standard deviation in bids submitted by builders. Therefore, the block proposer can potentially earn far more by picking one bid rather than another. Fairly frequently (at least, far more than I expected), this can be an order of magnitude more rewards.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>However, these larger bids typically come later in the slot. The risk that an operator faces by waiting to try and maximize rewards is to miss the block entirely and fail to propose at all. We know that the delay in receiving the payload from a relay can vary enormously, with some returning in less than 100ms and others regularly requiring upwards of 300ms. Errors do happen, meaning that no payload is delivered. Given the time constraints and up to 3000ms delays from relays until a timeout is sent, I would imagine that if an error is returned most will choose to not re-request from the relay and instead propose with the information that they have from others or locally built blocks, potentially missing superior bids.</span></p><h3 class="c6" id="h.d7gg6o7aqw83"><span class="c3">Understanding the Relay Data</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This payload tells us firstly, whether the operator has called the API and received a payload at all, which frequently is not the case because they only call this for the chosen bid. Secondly, from the builder bids data we can learn about the bids that the relay has delivered.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We can see when a specific validator is only receiving payloads from a set group of relays, but not others, ever.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We might want to try and understand why a validator is not accepting certain bids. Rejections could be because a validator is not using a given relay or any, they are accepting before a better bid appears, the bids are below their min-bid, or because an error occurred.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The most naive approach to discovering a validator min-bid is to identify the lowest bid that did not result in a payload and the highest bid that did result in a payload. We know their min-bid must be between these values, and so we can take the average of these values as the min-bid.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Rather than going block by block, we can look at specific NO&#39;s, as that&rsquo;s our goal. For each validator, an operator runs we know the address so we can get relay payload data for each validator and aggregate by the operator. Due to the number of validators that NO&#39;s run, it&rsquo;s necessary to be smart about when to call a relay.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We must first identify which validator proposes a block in the slot and then check this validator index against our list of known Lido indexes. Then, if the proposer is an address in our set we can call the relays to identify which, if any, delivered the payload. Then, get from the relays the list of bids submitted and decide which was the best possible bid the validator could have chosen. From this we can calculate the difference, or the &lsquo;missed&rsquo; earnings.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Generally, we see that Lido protocol NO&#39;s appear to be using a single min-bid across all validators. Where we can&rsquo;t be confident that this is true, this may be either due to incorrect data or more likely because the min-bid was implemented at different times for different clusters of validators. Therefore, even without requesting NO&#39;s to publicize their min-bid, we can fairly reliably decipher what it is.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">It&rsquo;s important to know what an operator has set their min-bid at because currently Lido DAO is not specifically tracking the MEV for the blocks that NO&#39;s create. We want to avoid NO&#39;s arbitrarily setting their min-bid too high, which would reduce rewards, and we want to monitor when builder bids are not being chosen, to ascertain the missed earnings. To do this reliably, we must know whether a min-bid threshold resulted in no payload, or if it was because of a request error / the operator didn&rsquo;t request at all.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">It&rsquo;s also possible that Lido DAO should request or require that NO&#39;s publicize their min-bid and update it frequently. If they did so, we could use this data instead, only using the above approach to verify and ensure that NO&#39;s are being truthful.</span></p><h3 class="c6" id="h.7y59k66n7c73"><span class="c3">Bids vs Time</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 289.33px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 289.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Above, we look at the value of bids by builders against when the bid is received. We&rsquo;ve normalized the timestamp against the timestamp of the first received bid for the block and normalized the value against the higher bid received in the block.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">What we can see is a fairly linear increase in value over time, with a 0.80 correlation between time and value. Hence, we know that on average, the longer that a validator waits before requesting bids from the relay the higher the value of the block. Of course, we must ensure that we&rsquo;re on time to avoid a missed proposal. But as we&rsquo;ll show, validators are typically requesting bids very early.</span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 372.00px;"><img alt="" src="images/image23.png" style="width: 624.00px; height: 372.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">What we can see is that the average winning bid is received by the relay 145ms BEFORE the slot begins. NO&#39;s are not waiting into the slot before calling the relays to get the best bids, select a bid and request the payload. Presumably, this is due to fear of missing a proposal.</span></p><p class="c1"><span class="c4"></span></p><h3 class="c6" id="h.f7zly8mvqpbv"><span class="c3">Payload vs Time</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 414.67px;"><img alt="" src="images/image30.png" style="width: 624.00px; height: 414.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">What we see is that the highest bids consistently come in after the selected bid, as would be expected. The median time difference is 761ms later, and this would allow the validator to capture an additional 0.0009 ETH per proposal, which is extremely close to the 0.001 that was found in the &Ouml;z et al paper. Notably, the median time difference is a little bit lower than they found, at 992ms. As they found, we see that almost all of the winning bids were selected before the highest bid being received by the relay.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We know that the average payload is received 145ms BEFORE the start of the slot, if the validator waited 761ms more they would be at 616ms into the slot. This time would still give them multiple seconds to propose the block and therefore it seems reasonable for validators to wait additional time to capture higher rewards. However, conversations with those more informed dispute this and so further research might be needed to understand feasibility.<br><br>A total of 9.8 ETH was uncaptured by Lido protocol validators in the 7 days as a result of accepting the earlier bid. This 9.8 ETH represents 5.62% of the rewards that were captured and so it&rsquo;s a fairly significant amount. Express another way, capturing these extra rewards would take APY from say 4% to 4.22%, and this difference is more than the difference between Lido and other competitors&#39; current APY. It&rsquo;s a meaningful amount that could benefit stakers.<br><br>Of course, not all of this extra could indeed be captured, so we would need to apply a cutoff and see what the surplus is before this cutoff. Deciding on this cutoff timestamp is outside of the scope of this research and will need input from NO&#39;s who have more context as to how much time they need to process and propose blocks. If waiting longer to capture these extra rewards resulted in more than a 5.62% increase in missed proposals, it would not be worth it.</span></p><p class="c1"><span class="c4"></span></p><h3 class="c6" id="h.i5v3q42tnxvn"><span class="c3">MEV vs Vanilla and Min-bid</span></h3><p class="c1"><span class="c4"></span></p><p class="c5"><span>When comparing MEV blocks to vanilla blocks, in the last 7-days of only Flashbots blocks proposed by Lido protocol validators, we see an MEV payment of 0.03 ETH. This is well below the 14-day average for all blocks of 0.06 ETH from </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://mevboost.pics/&amp;sa=D&amp;source=editors&amp;ust=1700278667429440&amp;usg=AOvVaw0f5uUz7pOBjJ1hZX4LbcxT">MEV-Boost Pics</a></span><span class="c2 c0">. This difference is likely simply due to the variance in block rewards skewing the mean so much. By only looking at half the time, for ~&frac14; of the proposed blocks and only for one relay, my data is less extensive and hence less useful for comparing against vanilla blocks.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>For the </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://www.rated.network/relays?network%3Dmainnet%26timeWindow%3D7d&amp;sa=D&amp;source=editors&amp;ust=1700278667429875&amp;usg=AOvVaw3KCItxLm7bNbCPqmJ9AjAC">last 7-days Rated</a></span><span class="c2 c0">&nbsp;execution rewards for mev-boost blocks had an average of 0.0799 in extra rewards. Of course, we must be careful when comparing in this way because it&rsquo;s plausible that many vanilla blocks are proposed because the mev-boost relay returned a lower value for that specific block. Or, not sufficiently above their min-bid threshold.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">So, it&rsquo;s not obvious that we can simply use a backward-looking rewards view to compare vanilla and mev-boost blocks when attempting to calculate the potential missed rewards. This Rated metric only tells us that proposed vanilla blocks had lower rewards, but we don&rsquo;t know why they chose a vanilla block.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Instead, we need to find all of the vanilla blocks that were proposed and look at the bids on relays for those blocks.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Unfortunately, when a proposer is not registered with a relay the builders will typically not submit bids and therefore we have no way of knowing the potential MEV value for these blocks. All we will see is blocks where the proposer IS registered with the relay but chose a vanilla block instead. This narrows our scope to only cases where the validator didn&rsquo;t call the relay, there was an error or the bids were not sufficiently high to be accepted over the vanilla block.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For our dataset of the past 7 days of all proposed blocks by Lido NO&#39;s we only have 503 (3.42% of the blocks) vanilla blocks. To be specific, these are blocks that do not have a relay tag in the Beaconcha.in data. Potentially these could be relay blocks, but they have not found a corresponding bid in the relay data and so are presumed to be vanilla. In the overall dataset for all validators globally there are 3431 vanilla blocks (6.81% of all proposed blocks in that period). In our limited data, Lido NO&#39;s are proposing vanilla blocks substantially less than the global mean.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We filter by blocks where the reward is greater than the vanilla block, and where that greater bid was received less than 1000ms into the slot.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">What we see is a mean MEV surplus of 0.049 ETH and a median of 0.02 ETH. For context, the mean timestamp at which the bid was received by the relay was 409ms after the start of the slot, and a 911ms median.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">With MEV surplus we see a heavy right-skew, meaning that the mean is being increased significantly by these higher rewards outliers. With the timestamps, we see the opposite, a left-skew where most of the received bids are higher, but a few were received before the slot, skewing the mean.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Using the median surplus and the mean timestamps will likely give us a reasonable estimation. That would estimate a surplus of 0.02 ETH could have been captured ~409ms after the beginning of the slot. This value aligns fairly well with our previous data because it fits the linear increase in possible rewards from the start of the slot up until 761ms where we saw the median highest bid for our larger dataset.</span></p><p class="c1"><span class="c4"></span></p><h3 class="c6" id="h.kyyroupd9sxt"><span class="c3">MEV by Operator</span></h3><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c2 c0">When we look by operator we see a big disparity.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 498.67px;"><img alt="" src="images/image27.png" style="width: 624.00px; height: 498.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">BridgeTower is unfortunate in that one of the vanilla blocks had a bid of 8.4 ETH, which skews their total missed earnings. Their median missed rewards by choosing vanilla over mev-boost was 0.022 ETH which is only marginally different from the median of the whole set which is 0.020 ETH.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Sigma Prime is the other outlier, with a median missed rewards per block of 0.020 ETH (hence the median for the set, given it&rsquo;s the vast majority of the blocks). While they have a lower total missed rewards, this is primarily down to the period examined. Over a longer period, we should see that Sigma Prime represents ~80% of the missed rewards because of choosing vanilla blocks over mev-boost, as this is their percentage of the total vanilla blocks for the set.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c32"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 428.00px; height: 247.00px;"><img alt="" src="images/image29.png" style="width: 428.00px; height: 247.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">In these 7 days, Sigma Prime could potentially have captured 9.3 ETH in additional rewards. Again, we need to stress that the amount they could earn will be highly dependent on when in the slot they need to receive a payload to avoid missing a proposal. This length of time will be highly dependent on their hardware, bandwidth, and latency with the relays. Lastly, again, we&rsquo;re only looking at Flashbots relay data here so the potential missed rewards could, and almost certainly are, larger because different relays will have different bids and the highest should be chosen.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Yet, when we look at the overall consensus block rewards earned by NO&#39;s over the months, we see that Sigma Prime ranks 1st among NO&#39;s in 3 of the 7 months reviewed, 4th twice, 9th once, and then most recently 10th.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Although they are proposing vanilla blocks much more frequently than is typical (~60% of the time over the last 30 days, compared to 2.6% for Lido overall), it&rsquo;s not causing them to earn less than the average</span><span>. However, that doesn&rsquo;t negate the fact that they could </span><span class="c7">potentially </span><span>be earning more - those missed rewards still existed.</span><span class="c2 c0">&nbsp;The unknown here is whether those missed rewards can be captured in a way that doesn&rsquo;t increase missed blocks due to MEV-boost. Much more detailed and further analysis is needed here.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Therefore, while </span><span class="c7">I don&rsquo;t think it&rsquo;s appropriate to score based on MEV currently</span><span class="c2 c0">, I do think it&rsquo;s important to track and consider whether more guidelines can be implemented for NO&#39;s. For example, to set a global min-bid more strictly, and lower, such as to capture a greater percentage of rewards. Currently, it appears that only Sigma Prime is implementing a meaningful min-bid that materially influences their percentage of vanilla blocks.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Lastly, a conversation should be had with NO&#39;s to work together to gauge what an appropriate time to request a payload from relays is. </span><span class="c2 c0">By optimizing this it&rsquo;s possible for Lido NO&#39;s to significantly increase rewards, as I&rsquo;ve shown here based on replicating previous research.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Further research should be able to ascertain precisely what min-bid should be set and the time at which validators should attempt to call relays to maximize rewards without increasing the amount of missed proposals. These small optimizations have the potential to further extend Lido&rsquo;s rewards gap against competitors, and most importantly to drive better returns for stakers.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Currently, it&rsquo;s not obvious that MEV data applies to a rating system. However, seeing that NO&#39;s can miss such a large amount of rewards and still rank well among Lido NO&#39;s for total consensus rewards suggests that consensus rewards and APY may be a better metric than is obvious at first. While there&rsquo;s a huge variance due to randomness, it&rsquo;s not so large as to skew the data to become useless. This is evident given that an operator can rank first in 3 of the 7 months, despite missing a huge amount of rewards available through mev-boost.</span></p><p class="c1"><span class="c4"></span></p><h1 class="c19" id="h.mqsfy0r1mjr1"><span class="c18 c7 c10">Consensus and Execution Client Diversity</span></h1><p class="c5"><span class="c4">Other great sources:</span></p><p class="c1"><span class="c4"></span></p><p class="c5"><span class="c21 c30"><a class="c23" href="https://www.google.com/url?q=https://mirror.xyz/jmcook.eth/S7ONEka_0RgtKTZ3-dakPmAHQNPvuj15nh0YGKPFriA&amp;sa=D&amp;source=editors&amp;ust=1700278667433885&amp;usg=AOvVaw3pm5zodJ0l26GSJH7Tb_nD">https://mirror.xyz/jmcook.eth/S7ONEka_0RgtKTZ3-dakPmAHQNPvuj15nh0YGKPFriA</a></span></p><p class="c5"><span class="c21 c30"><a class="c23" href="https://www.google.com/url?q=https://dankradfeist.de/ethereum/2022/03/24/run-the-majority-client-at-your-own-peril.html&amp;sa=D&amp;source=editors&amp;ust=1700278667434192&amp;usg=AOvVaw26ef91mkMApCxuQkJNlsCz">https://dankradfeist.de/ethereum/2022/03/24/run-the-majority-client-at-your-own-peril.html</a></span></p><p class="c5"><span class="c21 c30"><a class="c23" href="https://www.google.com/url?q=https://our.status.im/the-importance-of-client-diversity/&amp;sa=D&amp;source=editors&amp;ust=1700278667434421&amp;usg=AOvVaw06LTgR8OXaFPPjI796xRZl">https://our.status.im/the-importance-of-client-diversity/</a></span></p><p class="c5"><span class="c21 c30"><a class="c23" href="https://www.google.com/url?q=https://notes.ethereum.org/@afhGjrKfTKmksTOtqhB9RQ/BJGj7uh08&amp;sa=D&amp;source=editors&amp;ust=1700278667434636&amp;usg=AOvVaw1pzIqjC6U7i1uODIJsrFnD">https://notes.ethereum.org/@afhGjrKfTKmksTOtqhB9RQ/BJGj7uh08</a></span></p><p class="c1"><span class="c4"></span></p><h2 class="c11" id="h.s28bbmxfwswe"><span class="c18 c7 c10">Sourcing Client Data</span></h2><p class="c5"><span class="c2 c0">Currently, NOs self-report node and validator data, attesting to their usage of clients quarterly, which is aggregated at a Lido protocol level. This survey data includes the usage of systems like Vouch, which allows a node to utilize multiple clients and that makes reviewing the data a little more challenging.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>First, we&rsquo;ll look at publicly available data sources including Rated, </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://ethernodes.org/&amp;sa=D&amp;source=editors&amp;ust=1700278667435121&amp;usg=AOvVaw2AVfgfBAizr1k4MtReG6k9">EtherNodes</a></span><span>,</span><span>&nbsp;and </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://clientdiversity.org/&amp;sa=D&amp;source=editors&amp;ust=1700278667435295&amp;usg=AOvVaw2ADOvqKyPYxLiCf5fwVakQ">ClientDiversity.org</a></span><span class="c2 c0">&nbsp;data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>The below chart uses Rated data. Rated attempts to classify each validator based on its attesting and proposal behavior to estimate which consensus client it&rsquo;s likely using. They use the </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://github.com/sigp/blockprint&amp;sa=D&amp;source=editors&amp;ust=1700278667435627&amp;usg=AOvVaw14baqI5vpSinVxohQnzaj2">Sigma Prime &ldquo;blockprint&rdquo; &nbsp;fingerprinting code</a></span><span class="c2 c0">&nbsp;as a base, and they have built on top of this open-source library to try and improve their accuracy.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 374.67px;"><img alt="" src="images/image15.png" style="width: 624.00px; height: 374.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Importantly, what this data shows are the consensus clients that a validator is using. Therefore, it doesn&rsquo;t account for Vouch. With Vouch a node could be calling multiple consensus clients to get a response and then it will only attest and propose with one. For example, it might use Prysm, Lighthouse, and Nimbus to get a response but depending on the NO&#39;s configuration it will either vote with whichever appears to be the best response for that block, or it may always vote with a specific client unless there is an anomaly.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Given that it&rsquo;s built using Sigma Primes&#39; open-source fingerprinting code, the data here is fairly similar to what Sigma Prime shares. The last option is Miga Labs, which uses a crawler to count beacon nodes and their self-reported identity. However, this means that validators sharing a node are counted only once and nodes with fewer validators have a greater influence on the estimate. Therefore, what we would expect is that large NO&#39;s will be underrepresented, while solo NO&#39;s are overrepresented.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Today, the three datasets are highly similar, with only small differences in counts. However, that&rsquo;s not always the case.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Although there is no public historical data, I can attest that the variance between the three trackers fluctuates significantly, with periods where there has been up to double the count for given clients in Miga Labs vs Sigma Prime data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">More recently, this variance has been much lower. This is likely a function of the increased number of validators in the network. As the number of validators increases we would expect that the Sigma Prime and Rated fingerprinting approaches would become more accurate. As the average number of validators per node decreases, we should expect to see an increase in Miga Labs data, all else being equal.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">What we&rsquo;ve seen is the opposite, a massive increase in the number of validators relative to the number of nodes. Of course, node data is particularly poor so we shouldn&rsquo;t read too heavily into this, but it does imply that the Miga Labs crawler approach is likely suboptimal, presuming that we continue to see the number of validators grow faster than the number of nodes.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Under this paradigm, we&rsquo;d expect that classification becomes more accurate with a growing dataset. Where classification struggles are with less popular clients because of the smaller set of data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Both the Rated and Sigma Prime classifiers appear to rely on training a KNN model based on available graffiti. Using this graffiti they trust that it&rsquo;s accurate and can then assign these validators to a client.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Then, based on the attestations and proposals from these &lsquo;known&rsquo; clients they can start to identify which other validators exhibit similar behavior and classify them by client as such.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The accuracy of this fingerprinting is debated, with most of the issues arising around validators that are using Vouch or similar multiclient setups connected to multiple nodes with different clients. The complexity of scoring risk, when Vouch is used, is because Vouch adds an extra level of validation. It&rsquo;s not true that a block through Prysm has the same risk as a block through Prysm, using Vouch. If Prysm were to send a response that Vouch could not validate, it would reject it. So, when we look at fingerprinting data and identify that a Vouch setup used Prysm for X% of their blocks, that&rsquo;s not precisely the same as saying that a non-Vouch setup used Prysm for X% of their blocks.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">However, there is no clear solution to this problem. If we assume that Vouch reduces the risk of the underlying client, we&rsquo;ll only be overcounting risk, which is a much better outcome than the inverse.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>The fingerprinting will classify a given node as client A when it attests with the behavior of client A a very high percentage of the time, regardless of Vouch usage. I</span><span>t might not ONLY use client A, but if it&rsquo;s using it most of the time it&rsquo;s not entirely accurate to say that it&rsquo;s incorrectly identifying the client, only that it&rsquo;s failing to account for the usage of other clients, and the assumed risk reduction of Vouch, this is type II error.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>A fingerprinting system can be developed to better account for scenarios where multiple clients, similar to Vouch, are used for a single validator and Rated is actively working on this problem. </span><span>A split score or confidence interval approach might be sufficient here. Rather than trying to identify a specific validator as client A, for example, it&rsquo;s better to say that block X from validator Y is most like client A.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This block-based approach will better account for Vouch and also give us a more accurate representation of an NO&#39;s total usage when the risks are block-specific rather than underlying configuration-dependent. Currently, I&rsquo;m unsure whether Rated fingerprinting data is representing the data by validator, or by aggregated blocks per operator.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Sigma Prime and hence presumably Rated, struggles with classifying Nimbus particularly but is highly accurate for Prysm. Nimbus is often confused with Teku and Lighthouse, which could lead to artificial inflation in their usage. Broadly, Lighthouse and Prysm can be identified with very high precision. More information can be found here: </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://twitter.com/sproulM_/status/1440512518242197516&amp;sa=D&amp;source=editors&amp;ust=1700278667438622&amp;usg=AOvVaw1WvMaR5Jq9I0lYWveOumA8">https://twitter.com/sproulM_/status/1440512518242197516</a></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Given that our primary concern is around the most used clients, this gives us a high level of confidence in the data for usage in a scoring system.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">It&rsquo;s often said that identifying consensus clients is more challenging than execution clients, but I believe this is false. Most of the attempts at identifying execution clients rely on individual node data which as I&rsquo;ve explained is unhelpful with the increasing number of validators per node.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">With a presumed high usage of Geth, it makes classifying more challenging, compounded by the reduced amount of data that we can consume to identify execution clients. For classification you would need to rely mainly on block proposals and with the introduction of relays this becomes increasingly challenging. Therefore, current attempts at understanding usage from nodes and classification are likely to be poor.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Another data source comes from </span><span>execution-diversity.info, which surveyed large NOs about which clients they run</span><span class="c2 c0">. The survey is anonymized and isn&rsquo;t publicly used in any systems so we can start with a base assumption that these NO&#39;s are honest and have no incentive to misrepresent their setups. The surveyors estimate that 75% of the network validators are covered in their survey data and they presume that this data is likely similar to other large NO&#39;s on the network that aren&rsquo;t covered.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>However, it&rsquo;s unlikely to be representative of home stakers, who appear to represent a majority of nodes but a very small minority of validators.</span><span class="c2 c0">&nbsp;Therefore, there is a meaningful gap in the data, but it&rsquo;s possible that a combination of this survey data representing the large NOs and the node counting data from Ethernodes, representing the majority of nodes (more representative of smaller NO&#39;s) can be used to get a composite metric for usage across all validators.</span></p><p class="c1"><span class="c2 c0"></span></p><h4 class="c33" id="h.6fsaozvig2in"><span class="c0 c26">How ethernodes data is obtained</span></h4><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Ethernodes uses a node scraper that connects to a node that has a free peer, collects some data, and then disconnects. This means that if a node doesn&rsquo;t have any free peers, it will be invisible to the scraper. There are several things that can influence whether a node has free peers and those factors might be more or less relevant to certain clients, which would influence how &lsquo;visible&rsquo; they are to the scraper. For example, if a client&rsquo;s default peer count is set very high, it has more available slots and may therefore be more likely to have a free peer for the scraper to connect to. In this case, that client would be overrepresented in the data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Ethernodes data doesn&rsquo;t answer the question &ldquo;What is the client diversity of the overall network&rdquo; but rather &ldquo;What clients have the most free peers&rdquo;, with client diversity being only one variable in this equation.</span></p><h4 class="c33" id="h.o4v5e8phhqc"><span class="c26 c0">Comparing execution client data</span></h4><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Neither is perfect, and execution-diversity.info data will require manual check-ins to receive updates to the data but, without knowing how exactly ethernodes data correlates to overall diversity it cannot be used in isolation.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Lido VaNoM NO data shows that 78% of Lido validators are using Geth, which more closely aligns with the Execution-diversity.info survey data showing 84% usage than Ethernodes 55% usage. This is to be expected, as Lido NO&#39;s are highly represented in the survey data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For our purposes, the accuracy of global usage data is not highly important. All data sources show that Geth usage is above 50%. We know that the bulk of the risk exists when a client is being used for more than 33% of validators. As long as we can be confident that the data is not incorrectly showing a client as more than 33% when it&rsquo;s less, then the data is usable for our purposes.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">As execution client diversity increases it would be necessary to have more precise data, but currently, this is not an issue that we face. If there is a concern around the precision of the data then a scoring system can choose to only use this metric lightly in scoring.</span></p><h2 class="c11" id="h.qzbi9vv1ieub"><span class="c18 c7 c10">Client Risks</span></h2><p class="c1"><span class="c4"></span></p><p class="c5"><span>L</span><span class="c2 c0">et&rsquo;s consider what risks are posed by consensus and execution clients, whether they hold a supermajority or not. These are the cases that we can consider:</span></p><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_lkujsrvf7img-0 start" start="1"><li class="c5 c14 li-bullet-0"><span class="c2 c0">Double signing</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Mass offline event</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">Invalid blocks</span></li></ol><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>The split nature of consensus and execution in post-merge Ethereum introduces different points of failure, each with its implications. Let&#39;s dive into how an error in either the consensus client or the execution client can affect the chain and the validator&#39;s rewards and penalties.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">1. Error in the Consensus Client:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c2 c0">a. Block Proposer:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Wrong Block Proposals:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;Bugs in the consensus client cause it to propose blocks at incorrect times, with incorrect parent hashes, or with other invalid header data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">&lt; 33% usage: </span><span class="c2 c0">These blocks are primarily rejected. Result: Missed block proposal rewards.</span></p><p class="c5"><span class="c7">33% - 50% usage:</span><span class="c2 c0">&nbsp;Chain experiences increased instability. Result: Delayed finality, causing inactivity leak penalties.</span></p><p class="c5"><span class="c7">50% - 66% usage:</span><span class="c2 c0">&nbsp;High risk of chain forking. Result: Inactivity leak penalties on both forks.</span></p><p class="c5"><span class="c7">&gt; 66% usage:</span><span class="c2 c0">&nbsp;Faulty block proposals become the standard. Result: Compromised Ethereum chain integrity.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Fork Choice Rule Misinterpretation:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;The consensus client misinterprets the fork choice rule, proposing blocks on a non-canonical chain.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">&lt; 33% usage: </span><span class="c2 c0">The majority will ignore these blocks, resulting in missed rewards for the proposer.</span></p><p class="c5"><span class="c7">33% - 50% usage:</span><span class="c2 c0">&nbsp;Finality is delayed, causing an inactivity leak for all validators until finalization resumes.</span></p><p class="c5"><span class="c7">50% - 66% usage:</span><span class="c2 c0">&nbsp;A chain fork occurs, with inactivity leak penalties on both sides. Significant financial losses might ensue until a consensus is reached on the correct chain.</span></p><p class="c5"><span class="c7">&gt; 66% usage:</span><span class="c2 c0">&nbsp;The non-canonical chain becomes the dominant chain, compromising the integrity of Ethereum.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">b. Attester:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Double Voting:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;Bugs leading to double votes for multiple blocks in a single epoch.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">&lt; 33% usage:</span><span class="c2 c0">&nbsp;Due to such widespread usage, the correlation penalty ensures that the slashing per validator is extremely significant.</span></p><p class="c5"><span class="c7">&gt; 33% usage:</span><span class="c2 c0">&nbsp;100% of the ETH on the validator&#39;s impact is slashed.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Surround Voting:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;The client allows attestations that &quot;surround&quot; another.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">&lt; 33% usage:</span><span class="c2 c0">&nbsp;Due to such widespread usage, the correlation penalty ensures that the slashing per validator is extremely significant.</span></p><p class="c5"><span class="c7">&gt; 33% usage:</span><span class="c2 c0">&nbsp;100% of the ETH on the validator&#39;s impact is slashed.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Wrong Attestation:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Cause: </span><span class="c2 c0">The consensus client produces incorrect attestation data but without any slashable actions.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">&lt; 33% usage:</span><span class="c2 c0">&nbsp;Attestations are largely ignored, leading to missed rewards and potential penalties for these attestors but with no impact on finalization.</span></p><p class="c5"><span class="c7">33% - 50% usage:</span><span class="c2 c0">&nbsp;Increased chain instability and delayed finality. Inactivity leak penalties begin to affect all validators, particularly those attesting incorrectly.</span></p><p class="c5"><span class="c7">50% - 66% usage:</span><span class="c2 c0">&nbsp;The network sees two competing versions of the chain, leading to forks and inactivity leaks on both sides.</span></p><p class="c5"><span class="c7">&gt; 66% usage:</span><span class="c2 c0">&nbsp;The incorrect attestations become dominant, affecting the canonical chain&#39;s progression and integrity.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Mass Offline:</span></p><p class="c1 c39"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;Bugs preventing the consensus client from staying synchronized with the network or crashing frequently, leading to widespread validator inactivity.</span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1 c40"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">&lt; 33% usage: </span><span>The majority</span><span class="c2 c0">&nbsp;of the network remains active. Validators using the faulty client experience missed rewards.</span></p><p class="c5"><span class="c7">33% - 50% usage:</span><span class="c2 c0">&nbsp;A significant portion of the network goes offline. Finality is delayed, causing inactivity leak penalties to affect all validators, not just those using the faulty client.</span></p><p class="c5"><span class="c7">50% - 66% usage:</span><span class="c2 c0">&nbsp;The network struggles to reach consensus due to the mass offline event. Chain finality is at high risk, leading to widespread inactivity leak penalties with high impact.</span></p><p class="c5"><span class="c7">&gt; 66% usage:</span><span class="c2 c0">&nbsp;The Ethereum network grinds to a halt due to the mass offline event. Emergency interventions might be necessary to restore network operations. Meanwhile, there is a catastrophic inactivity leak causing enormous financial impact.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">2. Error in the Execution Client:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">a. Block Proposer:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Invalid Block Proposals:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;Execution client produces blocks with invalid state transitions or transactions.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">&lt; 33% usage:</span><span class="c2 c0">&nbsp;The majority rejects these blocks. Impacted validators experience missed block proposal rewards.</span></p><p class="c5"><span class="c7">33% - 50% usage:</span><span class="c2 c0">&nbsp;Chain instability due to increased invalid block proposals leading to inactivity leaks as the corrupted execution clients validate this incorrect block.</span></p><p class="c5"><span class="c7">50% - 66% usage:</span><span class="c0 c2">&nbsp;Risk of chain forking with inactivity leak penalties on both forks.</span></p><p class="c5"><span class="c7">&gt; 66% usage:</span><span class="c2 c0">&nbsp;Invalid blocks dominate the chain causing severe loss of trust and the potential request for a fork.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">State Miscalculations:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;Incorrect state computations by the execution client.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">&lt; 33% usage:</span><span class="c2 c0">&nbsp;The majority maintains the correct state, but the faulty proposers miss rewards.</span></p><p class="c5"><span class="c7">33% - 50% usage:</span><span class="c2 c0">&nbsp;Frequent chain reorgs as the network contends over the correct state. Inactivity leaks start affecting validators.</span></p><p class="c5"><span class="c7">50% - 66% usage:</span><span class="c2 c0">&nbsp;Risk of a chain fork based on differing state views. Both sides suffer from inactivity leaks.</span></p><p class="c5"><span class="c7">&gt; 66% usage:</span><span class="c2 c0">&nbsp;The network may largely operate in an incorrect state, disrupting Ethereum&#39;s proper functioning.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">b. Attester:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Attesting to Invalid Blocks:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;Attesting to blocks with incorrect state or invalid transitions.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c7 c10"></span></p><p class="c5"><span class="c7">&lt; 33% usage:</span><span class="c2 c0">&nbsp;The majority ignores these attestations. As a result, the attesters missed attestation rewards.</span></p><p class="c5"><span class="c7">33% - 50% usage:</span><span class="c2 c0">&nbsp;Chain instability due to conflicting attestations, causing delayed finality and inactivity leaks.</span></p><p class="c5"><span class="c7">50% - 66% usage:</span><span class="c2 c0">&nbsp;The chain risks forking, causing larger inactivity leaks.</span></p><p class="c5"><span class="c7">&gt; 66% usage:</span><span class="c2 c0">&nbsp;Majority attests to invalid blocks. Result in compromised Ethereum chain integrity.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Mass Offline:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Cause:</span><span class="c2 c0">&nbsp;Bugs causing the execution client to crash or become non-responsive, preventing validators from proposing valid blocks or making accurate attestations.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c7 c10">Consequences:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">&lt; 33% usage: </span><span>The majority</span><span class="c2 c0">&nbsp;of the network remains active. Validators using the faulty client experience missed rewards.</span></p><p class="c5"><span class="c7">33% - 50% usage:</span><span class="c2 c0">&nbsp;A significant portion of the network goes offline. Finality is delayed, causing inactivity leak penalties to affect all validators, not just those using the faulty client.</span></p><p class="c5"><span class="c7">50% - 66% usage:</span><span class="c2 c0">&nbsp;The network struggles to reach consensus due to the mass offline event. Chain finality is at high risk, leading to widespread inactivity leak penalties with high impact.</span></p><p class="c5"><span class="c7">&gt; 66% usage:</span><span class="c2 c0">&nbsp;The Ethereum network grinds to a halt due to the mass offline event. Emergency interventions might be necessary to restore network operations. Meanwhile, there is a catastrophic inactivity leak causing enormous financial impact.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We can try to gauge the likelihood of these events and their severity. We rank from 1 to 5, with 1 being the lowest likelihood, network, and operator impact, and 5 the opposite:</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c1"><span class="c2 c0"></span></p><a id="t.fe89dc31f6e91ddf73eb020f147a5ce853eea1df"></a><a id="t.0"></a><table class="c34"><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c7 c10">Client</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c7 c10">Cause</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c7 c10">Likelihood</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c7 c10">Network Impact</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c7 c10">Operator Impact</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c7 c10">Product</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Consensus</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Wrong Block Proposals</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">1</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">10</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Consensus</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Fork Choice Rule Misinterpretation</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">1</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">10</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Consensus</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Double Voting</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">1</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">1</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Consensus</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Surround Voting</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">1</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">1</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Consensus</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Wrong Attestation</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">3</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">30</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Consensus</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Mass Offline</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">4</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">4</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">16</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Execution</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Invalid Block Proposals</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">20</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Execution</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">State Miscalculations</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">20</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Execution</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Attesting to Invalid Blocks</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">5</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">2</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">20</span></p></td></tr><tr class="c25"><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Execution</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">Mass Offline</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">4</span></p></td><td class="c13" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">4</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">3</span></p></td><td class="c8" colspan="1" rowspan="1"><p class="c9"><span class="c2 c0">24</span></p></td></tr></table><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>These values are highly subjective, but this is my best impression of where the risks are with consensus and execution clients. </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://dankradfeist.de/ethereum/2022/03/24/run-the-majority-client-at-your-own-peril.html&amp;sa=D&amp;source=editors&amp;ust=1700278667464338&amp;usg=AOvVaw1xtyXzIg2J2BZdT2WSER02">Dankrad Feist</a></span><span class="c2 c0">&nbsp;inspired this analysis structure. He combined impact into a single metric, but I think it&rsquo;s better to consider separately the impact on the network and then the financial impact on the operator.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">In the case of a mass offline event, it has a large impact on the network because it could prevent finality and allows for malicious NO&#39;s to more easily conduct attacks. Yet, for a consensus client bug to cause the offline events the financial impact would be less than for an execution client bug because the breadth of downtime would cause a smaller inactivity leak.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Like Fiest, my conclusion is that the largest risk is posed by an invalid block, despite less immediate financial impact to the NO&#39;s. Invalid blocks break the trust of the chain and that fundamentally undermines its purpose. Then, mass downtime is the second largest risk, with the risk of slashing events coming last due to their likelihood.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We also see that despite there being more possible issues for consensus clients, the scale of the impact is reduced because of greater diversity. Hence, while there are extreme risks for both clients, the lack of diversity in execution clients makes it more concerning for me, despite having a longer and stronger track record.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When we look at the causes of the events, presuming they occur, it&rsquo;s primarily as a result of clients attesting to invalid blocks. If a single validator proposes an incorrect block but every other validator rejects it, there is no issue. The issue only occurs when there is usage of a client, either execution or consensus, from both the proposer and a large percentage of those validators attesting.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>In his blog post about client diversity, </span><span class="c22 c7"><a class="c23" href="https://www.google.com/url?q=https://mirror.xyz/jmcook.eth/S7ONEka_0RgtKTZ3-dakPmAHQNPvuj15nh0YGKPFriA&amp;sa=D&amp;source=editors&amp;ust=1700278667465563&amp;usg=AOvVaw38iiaNjoM3iibc-CGHLwt-">Jim McDonald therefore suggests</a></span><span class="c2 c0">&nbsp;that it&rsquo;s acceptable, perhaps even ideal, to use popular clients for proposals but not for attestations. On the consensus layer, this is perhaps true when the usage is less than ~50%. For the execution layer, there is a significant supermajority currently and therefore it&rsquo;s highly risky to use it for either attestations or proposals.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">There is an enormous difference in risk between clients having less or more than 33% usage. However, when we think about using this for scoring NO&#39;s we need to think about both the risk for the network, but also for the Lido set of validators itself.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Let&rsquo;s consider the expected change in risk if Lido NO&#39;s chose to diversify their client usage much more, to the extreme of using each client equally. We can assume there are six popular consensus clients and four execution clients.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For slashing events the Lido set now faces a much smaller risk of slashing from client bugs, assuming that a bug exists only in a single client.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">If we consider the Lighthouse risk, a bug causing slashing for all Lighthouse validators globally would have 32 ETH in slashing per validator because of the high correlation penalty. In the case where Lido had lower exposure, the same event caused 27.5 ETH in slashing per validator. Taking Lidos exposure from 33% of ETH lost to 14.3%, because not only is the correlation penalty reduced due to lower global usage but also our net exposed number of validators.</span></p><p class="c5"><span class="c2 c0"><br>We know that the correlation penalty reaches its max when &#8531; of the network is slashed and so again, this imposes the importance of clients having lower than &#8531; usage globally.<br><br>Yet, if we look at Prysm, taking Lido exposure from 23.1% to 16.6% does not reduce the correlation penalty, it only reduces the total loss because of the reduced number of validators exposed.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 432.00px;"><img alt="" src="images/image19.png" style="width: 624.00px; height: 432.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">We can see that the curves for each client are very different and that&rsquo;s because of the global usage, regardless of Lido usage. For example, if if a single Lido validator runs Prysm it will still be slashed for 100% of its ETH in the case of a client bug causing slashing because Prysm has greater than &#8531; usage across the network.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Therefore, we can argue that the data suggests that the appropriate usage of clients for the Lido set will be different for each client. However, we can&rsquo;t only think about a slashing event, we need to consider other risks, particularly as we&rsquo;ve identified that slashing is one of the lower-importance risks, though, the most financially impactful to each validator involved.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The three other scenarios to consider are the inactivity leak, missed rewards/penalties and the finalization of incorrect blocks.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Let&rsquo;s tackle missed rewards and penalties first, as it&rsquo;s the simplest. These will scale linearly with the usage of a client inside of the set and the global usage here is irrelevant to our financial impact.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Finalization of incorrect blocks can only occur when the network has greater than 50% concentration, and this would still give participants time to try to rectify the situation during the inactivity leak. With more than 66% concentration, as with geth, finalization will be nearly unavoidable, and this depends on global usage, not just Lido. However, given that Lido is ~&#8531; of the network, we must consider that our usage does have a large impact on the global concentration, particularly with geth. For example, zero geth usage in Lido would instantly ensure that geth is no longer a supermajority.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 286.67px;"><img alt="" src="images/image16.png" style="width: 624.00px; height: 286.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For the inactivity leak, the financial impact on Lido depends on:</span></p><p class="c1"><span class="c2 c0"></span></p><ol class="c27 lst-kix_cr8bzav1190f-0 start" start="1"><li class="c5 c14 li-bullet-0"><span class="c2 c0">The % of Lido validators using the impacted client</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">The time it takes NO&#39;s to get back online, either using an alternative client or with a fixed version of the impacted client</span></li><li class="c5 c14 li-bullet-0"><span class="c2 c0">The time that the inactivity leak lasts, which is variable based on the global client usage if we exclude 2.</span></li></ol><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">If we presume that the 2nd component is fixed regardless of which client is used, then the only variables are the global usage and the Lido usage of the client. This simplifies the situation, of course, but not to the extent of being an ineffective review.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The governing factor will be the level of Lido usage because although those unimpacted by the client bug can still receive penalties as a result of normal downtime, it&rsquo;s not quadratic like those impacted. Therefore, again, the dominant factor in the total Lido penalties accrued is the variable number of Lido validators running the impacted client.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 337.33px;"><img alt="" src="images/image10.png" style="width: 624.00px; height: 337.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 337.33px;"><img alt="" src="images/image3.png" style="width: 624.00px; height: 337.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">This supermajority on the execution client side is suboptimal. However, we need to consider what risk this poses to the network. With a consensus bug or attack, we would expect to see different votes and this could lead to an inability to finalize, or incorrect blocks being accepted. With an execution client bug or attack, we could see issues in transaction handling and the construction of payloads. Depending on the issue, we might see that the execution client never produces a payload, preventing the validator from submitting a block with transactions, but it likely can still submit some block. In another case, we might see that the constructed payload and transaction handling result in a payload that the consensus client cannot handle, and this would result in a missed block or even an incorrect block.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Of course, an inactivity leak because of a client bug can only occur when that client is more than 33% of the network so it&rsquo;s also important that we track this global usage.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Again, it&rsquo;s clear that risk starts to become more significant when the global usage of a client is higher than 33%. But ideally, we would see usage below this, because slashing risk will reduce linearly as usage decreases.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Internally, the correct level of Lido usage will depend on the broader global usage. It might be possible for the DAO to identify some correct level for another metric that can be applied broadly, and that will then dictate the correct usage. For example, by aiming to limit the maximum slashing risk because of a client bug to 20% of the total Lido ETH, this would allow us to create a scoring system that scores NO&#39;s lower when the total Lido usage of clients is above ~20% for Prysm, ~22% for Lighthouse and ~28% for Teku. Where precisely this &ldquo;cutoff&rdquo; starts is somewhat subjective, but the above data can help determine it because it will allow the thresholds to adjust over time with the usage data. Given that we would want to avoid a scenario whereby NO&#39;s are incentivized to regularly change clients, which introduces a new host of issues, any scoring system will need to use a light touch when client usage is not extreme.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The final case to consider is Vouch. Given the large number of possible configurations, we must use a rule of thumb that can be broadly applied to Vouch. My prior is that Vouch is a net positive for NO&#39;s, and that its use should be encouraged. However, there does again reach a level of usage that starts to introduce risk. Although Vouch cannot directly sign and therefore does not have the same risk profile as clients, it does have the potential to cause downtime in the case of a bug that prevents Vouch from outputting a result. Hence, we must also consider the risk of this downtime and how it would financially impact us. Broadly, this risk is only significant in the case of very high usage in the Lido set, or when global usage is more than 33% of the network. Tracking Vouch usage via fingerprinting is extremely challenging, which currently prevents us from obtaining any reliable data on network-wide use. Currently, I have no good suggestion on how to monitor and score Vouch usage directly.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For scoring the underlying clients being used as part of a Vouch configuration, we have two possible approaches. The first would be to use fingerprinting data by NO&#39;s, such as the Rated or Sigma Prime data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The advantage to this is that it looks at the actual attestations and blocks proposed by a validator and classifies that validator as a single client. This approach is helpful when we want to factor in the actual usage of the clients that are connected to Vouch. For example, although you may configure Vouch with say 3 clients, if client A is making the vast majority of attestations, it might be more appropriate to use the fingerprinting data which counts this cluster of validators as more than 33% for client A, despite it being configured with 3 clients.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The downside is that the fingerprinting is fairly brute force, and so if a cluster of validators with this configuration happens to attest on average with client A, it might only classify them as client A. Here we get both type I and type II errors, but for our scoring system the most impactful is likely to be type II, the non-counting of usage of a client that truly is being used i.e. we&rsquo;re not correctly identifying our true risk exposure. While overcounting risk exposure could negatively impact a specific operator, for the Lido set this is a smaller issue than undercounting our true risks.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The second approach would be to survey NO&#39;s, as is done quarterly currently, on their client usage and to request additional information about their precise Vouch configurations. Knowing that a specific cluster of validators is using Teku, Nimbus, and Lighthouse in a configuration that doesn&rsquo;t wait for full agreement would allow us to assign &#8531; usage to each.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The downside to this approach is that we assign usage and calculate risk based on configuration, not on the actual attestations and block proposals made. Again, Teku might be dominating the actual usage here and that would not be represented via this survey approach. The upside is that we reduce our type 2 error per client by at least assigning &#8531; of the risk to each.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">When Vouch is working correctly, the downtime of a specific client should have a minor impact, as it will use responses from those nodes that are still online. Therefore, the risks are primarily around invalid blocks and slashing.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Here, the risks occur based on the content of the attestations and block proposals, and so which client is being used in reality is more important than the actual configuration. Hence, my suggestion is that we rely more heavily on fingerprinting data than on survey data.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Although it has issues with accuracy, it will still be more accurate than the survey, because a client can be configured into Vouch and yet never be responsible for an attestation or proposal. If folks believe there is a need, it would be possible to combine the fingerprinting and survey data to create a composite score, which is likely to reduce type 2 errors, by increasing type 1 errors, which may be an acceptable tradeoff.</span></p><p class="c1"><span class="c4"></span></p><h2 class="c11" id="h.7lah3lvh50rr"><span class="c18 c7 c10">Identifying Lido NO&#39;s Client Usage</span></h2><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For network data, we must rely on public sources that we&rsquo;ve discussed already. But for Lido protocol validators we have direct contact with the NO&#39;s and hence we have an opportunity to gather more accurate data on our specific set of validators.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>There are two reasonable approaches; either conduct a periodic survey (similar to VaNoM) or require that </span><span>Lido NO&#39;s use graffiti for signing.</span><span class="c2 c0">&nbsp;In the future it may be possible for clients to write data into the blocks detailing which client is used - though this isn&rsquo;t currently the case, Lido DAO may have some power to push for clients to include this feature.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Graffiti has the nice characteristic of being saved to history forever, making it easy to cross-reference in the case of an operator being accused of lying about their true client usage. Likewise, by being on-chain it would allow a scoring system run on-chain to more easily access this information, though the feasibility of doing this at scale could be problematic, I have little context here.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">For both graffiti and the survey we rely on the NO&#39;s being truthful. However, any claims can be checked. I believe that the fingerprinting data available currently is highly accurate at identifying what client a validator is using. It struggles at counting the potential clients used by nodes connected to Vouch, but this shouldn&rsquo;t impact the success of the classifier at identifying the primarily used clients by the validator.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Based on this graffiti it will be possible to check it against the fingerprinting data. Given that the graffiti will be representative of the actual client used for the attestation or proposal, Vouch is irrelevant here. If there is a significant discrepancy to create suspicion this could initiate a more manual investigation to understand the difference and validate the truthfulness of the graffiti.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Lido already enforces certain standards like requiring that NO&#39;s utilize at least one relay from the &ldquo;must-use&rdquo; relay set. Therefore, it doesn&rsquo;t seem unfair or onerous to require that NO&#39;s use graffiti to disclose their client usage.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The major benefits of using graffiti over a periodic survey are that it should be more real-time and it will contribute to the accuracy of the fingerprinting. These systems utilize graffiti and so by increasing the usage of graffiti, the classifier should become more accurate.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Lastly, a more accurate but perhaps more onerous suggestion was inspired by Jim McDonald. It might be possible to have NO&#39;s run a batch script that would share certain information. Taken to the extreme, it could be possible to use such a script for NO&#39;s to share information about their hardware, setup, and client usage. Although I imagine that this would be unpopular, it&rsquo;s the most accurate approach to obtaining off-chain data.</span></p><h2 class="c11" id="h.f1bnp68sekm8"><span class="c18 c7 c10">Web3Signer, Dirk, Key Management Software</span></h2><p class="c5"><span class="c2 c0">We&rsquo;ve established that much of the Lido risk exists with the NO&#39;s procedures and policies. Key management is a particular concern and ideally would be an appropriate way to monitor and potentially score NO&#39;s.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The issue is with data. There is currently zero public data around key management nor for the Lido NO&#39;s. Even if data were to exist, it&rsquo;s hard to imagine how it could exist in a numerical format that could be consumed into an automated scoring system.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Hypothetically, we would want to understand the number of unique withdrawal keys that exist for the NO&#39;s set, how they are stored, and in what size clusters are they stored. Using a single withdrawal key for multiple validators makes that single key more valuable, which is more likely to result in attempts to steal the key. However, storing multiple keys in the same place leads to the same problem, so multiple keys will need to be physically or logically separated to reduce the impact of any loss.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Validator keys provide no access to funds themselves. Indirect attacks such as blackmail are possible, as are spoiling attacks where the attacker&#39;s goal is for you to lose funds rather than for the attacker to gain them.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">As of November 2022 Lido NO&#39;s were using:</span></p><p class="c1"><span class="c2 c0"></span></p><a id="t.7829124f25de7d53baed1a9f4242065a75c09675"></a><a id="t.1"></a><table class="c34"><tr class="c31"><td class="c36" colspan="1" rowspan="1"><p class="c20"><span class="c2 c7 c10">Node NO&#39;s</span></p></td><td class="c42" colspan="1" rowspan="1"><p class="c20"><span class="c2 c7 c10">Dirk</span></p></td><td class="c29" colspan="1" rowspan="1"><p class="c20"><span class="c2 c7 c10">Web3Signer</span></p></td><td class="c35" colspan="1" rowspan="1"><p class="c20"><span class="c2 c7 c10">No External Signer</span></p></td></tr><tr class="c44"><td class="c28" colspan="1" rowspan="1"><p class="c20"><span class="c2 c0">27</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c20"><span class="c2 c0">26%</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c20"><span class="c2 c0">19%</span></p></td><td class="c37" colspan="1" rowspan="1"><p class="c20"><span class="c2 c0">59%</span></p></td></tr></table><p class="c1"><span class="c2 c0"></span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">The usage of an external signer can greatly increase key security. Given this is the only data available, the DAO may consider whether it&rsquo;s reasonable to score NO&#39;s lower if they do not use an external signer.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span>Broadly, I think the benefits of using an external signer far outweigh the cons and so a scoring system that incentivizes NO&#39;s to use an external signer is something I would support. A second consideration would be how precisely the external signer is being used, which is equally important, but likely this stretches into the realm of being too hard to score.</span></p><h1 class="c19" id="h.73um5rnmmpvb"><span class="c18 c7 c10">Conclusion</span></h1><p class="c5"><span class="c2 c0">Our focus is on developing a NO scoring system that effectively balances stakeholder rewards with risk mitigation. While NO&rsquo;s can influence the rewards their validators earn, they have far greater control and responsibility for minimizing penalties and slashing. Therefore, optimizing for these risk mitigation factors should be a better proxy for long-term performance.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">By viewing a scoring system through the lens of risk, it will allow us to craft a healthy and resilient validator set, that should necessitate higher performance over infinite epochs.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c2 c0">Our investigation centers on identifying potential data sources and metrics crucial for an effective NO scoring system. We explore both on-chain and off-chain factors, recognizing their distinct impacts on overall NO performance and risk management. On-chain, we analyzed millions of data points to identify whether the datasets have the characteristics necessary to be used in scoring.</span></p><p class="c1"><span class="c2 c0"></span></p><h3 class="c6" id="h.6ch8d44spb24"><span class="c3">Key Findings and Recommendations</span></h3><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Limitations of On-Chain Data-Only Systems:</span><span class="c2 c0">&nbsp;While it is feasible to create a NO scoring system solely based on on-chain performance data, such a system would be substantially deficient. It would fail to comprehensively account for the myriad of risk factors, which are pivotal in ensuring a robust and reliable scoring system. We found that overwhelmingly risk mitigation data was necessary for the creation of any NO scoring system. Without it, any other system would optimize for another outcome, without any insight and transparency into the unknown accumulation of these risk factors. Therefore, an on-chain data-only approach would be considerably limited in its effectiveness.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Priority of Off-Chain Risk Data:</span><span class="c2 c0">&nbsp;Our research underscores the paramount importance of off-chain risk data in any effective scoring system. While this necessitates a departure from a fully trustless scoring system, it&#39;s a necessary compromise to achieve a realistic assessment of NO performance.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Risk-Based Scoring Framework:</span><span class="c2 c0">&nbsp;The scoring system should prioritize minimizing penalties and slashing, key factors in long-term performance and stability. Key risk factors include internal processes, hardware, client and server locations, jurisdiction, and operator concentration.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Incorporating On-Chain and Off-Chain Data:</span><span class="c2 c0">&nbsp;The system should utilize a blend of on-chain data and critical off-chain risk data. This approach acknowledges the necessity of human involvement and increased transparency from NOs for a comprehensive risk assessment. Gathering this data is likely to conflict with a transition to permissionless anonymous NO&rsquo;s. We find that it will be critical to create an incentive structure for NO&rsquo;s to truthfully disclose information and a remediation system to investigate discrepancies. Without this information, the DAO has little transparency into the accumulation of risk in these factors and hence cannot properly maintain the health of the set.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">MEV Data Exploration:</span><span class="c2 c0">&nbsp;Our study has identified MEV (Maximal Extractable Value) data as an intriguing area for future exploration. This includes potential optimizations for capturing MEV and tracking/preventing MEV theft by operators. However, currently, MEV data is not a viable metric for the scoring system due to implementation challenges and its relative unreliability as a dataset.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Data Source Reliability and Selection:</span><span class="c2 c0">&nbsp;Rated.network is identified as a suitable source for on-chain data, given its accuracy and robust API.</span></p><p class="c1"><span class="c2 c0"></span></p><p class="c5"><span class="c7">Community Engagement:</span><span class="c2 c0">&nbsp;Engaging with the Lido DAO community is crucial, especially around areas like client diversity, MEV strategies, and key management, to ensure the scoring system aligns with community values and risk tolerance. We find that the DAO may benefit from creating stricter mandates for NO&rsquo;s regarding systems, internal processes, and information disclosure. The economic value to NO&rsquo;s from participation in Lido is immense and hence the DAO has significant power to enforce standards that will allow for the creation of a stronger scoring system and a healthier validator set.</span></p></body></html>
